<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Takeshi Fujii, MD">
<meta name="dcterms.date" content="2025-04-20">

<title>Final Project: Deep Learning for Breast Cancer Detection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-53f539a478d6ecd1be31ce9fd30fd81c.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8a894fcc3cb5e37eb5bf30def131be2f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">


<meta name="citation_title" content="Final Project: Deep Learning for Breast Cancer Detection">
<meta name="citation_author" content="Takeshi Fujii, MD">
<meta name="citation_publication_date" content="2025-04-20">
<meta name="citation_cover_date" content="2025-04-20">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-04-20">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=World-leading AI trial to tackle breast cancer launched;,citation_author=gov.uk;,citation_publication_date=2025-02;,citation_cover_date=2025-02;,citation_year=2025;,citation_journal_title=Press release;">
<meta name="citation_reference" content="citation_title=A curated mammography data set for use in computer-aided detection and diagnosis research;,citation_abstract=Abstract Published research results are difficult to replicate due to the lack of a standard evaluation data set in the area of decision support systems in mammography; most computer-aided diagnosis (CADx) and detection (CADe) algorithms for breast cancer in mammography are evaluated on private data sets or on unspecified subsets of public databases. This causes an inability to directly compare the performance of methods or to replicate prior results. We seek to resolve this substantial challenge by releasing an updated and standardized version of the Digital Database for Screening Mammography (DDSM) for evaluation of future CADx and CADe systems (sometimes referred to generally as CAD) research in mammography. Our data set, the CBIS-DDSM (Curated Breast Imaging Subset of DDSM), includes decompressed images, data selection and curation by trained mammographers, updated mass segmentation and bounding boxes, and pathologic diagnosis for training data, formatted similarly to modern computer vision data sets. The data set contains 753 calcification cases and 891 mass cases, providing a data-set size capable of analyzing decision support systems in mammography.;,citation_author=Rebecca Sawyer Lee;,citation_author=Francisco Gimenez;,citation_author=Assaf Hoogi;,citation_author=Kanae Kawai Miyake;,citation_author=Mia Gorovoy;,citation_author=Daniel L. Rubin;,citation_publication_date=2017-12;,citation_cover_date=2017-12;,citation_year=2017;,citation_issue=1;,citation_doi=10.1038/sdata.2017.177;,citation_issn=2052-4463;,citation_volume=4;,citation_language=en-US;,citation_journal_title=Scientific Data;">
<meta name="citation_reference" content="citation_title=An open codebase for enhancing transparency in deep learning-based breast cancer diagnosis utilizing CBIS-DDSM data;,citation_author=Ling Liao;,citation_author=Eva M. Aagaard;,citation_publication_date=2024-11;,citation_cover_date=2024-11;,citation_year=2024;,citation_issue=1;,citation_doi=10.1038/s41598-024-78648-0;,citation_issn=2045-2322;,citation_volume=14;,citation_language=en-US;,citation_journal_title=Scientific Reports;">
<meta name="citation_reference" content="citation_title=Mammography with deep learning for breast cancer detection;,citation_abstract=X-ray mammography is currently considered the golden standard method for breast cancer screening, however, it has limitations in terms of sensitivity and specificity. With the rapid advancements in deep learning techniques, it is possible to customize mammography for each patient, providing more accurate information for risk assessment, prognosis, and treatment planning. This paper aims to study the recent achievements of deep learning-based mammography for breast cancer detection and classification. This review paper highlights the potential of deep learning-assisted X-ray mammography in improving the accuracy of breast cancer screening. While the potential benefits are clear, it is essential to address the challenges associated with implementing this technology in clinical settings. Future research should focus on refining deep learning algorithms, ensuring data privacy, improving model interpretability, and establishing generalizability to successfully integrate deep learning-assisted mammography into routine breast cancer screening programs. It is hoped that the research findings will assist investigators, engineers, and clinicians in developing more effective breast imaging tools that provide accurate diagnosis, sensitivity, and specificity for breast cancer.;,citation_author=Lulu Wang;,citation_publication_date=2024-02;,citation_cover_date=2024-02;,citation_year=2024;,citation_doi=10.3389/fonc.2024.1281922;,citation_issn=2234-943X;,citation_volume=14;,citation_language=en-US;,citation_journal_title=Frontiers in Oncology;">
</head>

<body class="quarto-light">

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Final Project: Deep Learning for Breast Cancer Detection</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Authors</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Takeshi Fujii, MD </p>
          </div>
                      <div class="quarto-title-meta-contents">
            <p class="author"> </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        BSc Computer Science, The University of London
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
                <div>
            <div class="quarto-title-meta-heading">Published</div>
            <div class="quarto-title-meta-contents">
              <p class="date">20 April 2025</p>
            </div>
          </div>
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="report.pdf"><i class="bi bi-file-pdf"></i>PDF</a></p></div></div></div>
    </div>



    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">1. Introduction</a>
  <ul class="collapse">
  <li><a href="#background-motivation" id="toc-background-motivation" class="nav-link" data-scroll-target="#background-motivation">1.1 Background &amp; Motivation</a></li>
  <li><a href="#objectives" id="toc-objectives" class="nav-link" data-scroll-target="#objectives">1.2 Objectives</a></li>
  <li><a href="#scope" id="toc-scope" class="nav-link" data-scroll-target="#scope">1.3 Scope</a></li>
  </ul></li>
  <li><a href="#dataset" id="toc-dataset" class="nav-link" data-scroll-target="#dataset">2. Dataset</a>
  <ul class="collapse">
  <li><a href="#dataset-description" id="toc-dataset-description" class="nav-link" data-scroll-target="#dataset-description">2.1 Dataset Description</a></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing">2.2 Preprocessing</a></li>
  <li><a href="#splitting-strategy" id="toc-splitting-strategy" class="nav-link" data-scroll-target="#splitting-strategy">2.3 Splitting Strategy</a></li>
  </ul></li>
  <li><a href="#deep-learning-workflow" id="toc-deep-learning-workflow" class="nav-link" data-scroll-target="#deep-learning-workflow">3. Deep Learning Workflow</a>
  <ul class="collapse">
  <li><a href="#problem-definition" id="toc-problem-definition" class="nav-link" data-scroll-target="#problem-definition">3.1 Problem Definition</a></li>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">3.2 Data Preparation</a></li>
  <li><a href="#model-building" id="toc-model-building" class="nav-link" data-scroll-target="#model-building">3.3 Model Building</a></li>
  <li><a href="#model-training" id="toc-model-training" class="nav-link" data-scroll-target="#model-training">3.4 Model Training</a></li>
  <li><a href="#evaluation" id="toc-evaluation" class="nav-link" data-scroll-target="#evaluation">3.5 Evaluation</a></li>
  <li><a href="#model-improvement" id="toc-model-improvement" class="nav-link" data-scroll-target="#model-improvement">3.6 Model Improvement</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">4. Results</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">5. Discussion</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">6. Conclusion</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">7. References</a></li>
  <li><a href="#appendix" id="toc-appendix" class="nav-link" data-scroll-target="#appendix">Appendix</a>
  <ul class="collapse">
  <li><a href="#a.-code-snippets" id="toc-a.-code-snippets" class="nav-link" data-scroll-target="#a.-code-snippets">A. Code Snippets</a></li>
  <li><a href="#b.-hyperparameter-table" id="toc-b.-hyperparameter-table" class="nav-link" data-scroll-target="#b.-hyperparameter-table">B. Hyperparameter Table</a></li>
  <li><a href="#c.-full-model-architecture" id="toc-c.-full-model-architecture" class="nav-link" data-scroll-target="#c.-full-model-architecture">C. Full Model Architecture</a></li>
  <li><a href="#d.-data-statistics" id="toc-d.-data-statistics" class="nav-link" data-scroll-target="#d.-data-statistics">D. Data Statistics</a></li>
  <li><a href="#e.-report-writing-tools" id="toc-e.-report-writing-tools" class="nav-link" data-scroll-target="#e.-report-writing-tools">E. Report Writing Tools</a></li>
  </ul></li>
  <li><a href="#references-1" id="toc-references-1" class="nav-link" data-scroll-target="#references-1">References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">Abstract</h2>
<ul>
<li>One-paragraph summary of the problem, dataset, methodology, and main findings.</li>
<li>One-paragraph summary of the problem, dataset, approach, and key results.</li>
</ul>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">1. Introduction</h2>
<section id="background-motivation" class="level3">
<h3 class="anchored" data-anchor-id="background-motivation">1.1 Background &amp; Motivation</h3>
<ul>
<li>Describe the clinical and societal significance of early breast cancer detection.</li>
<li>Mention the NHS 2025 initiative and how AI fits into screening.</li>
</ul>
<p><img src="figures/mammogram.jpg" class="center img-fluid" style="width:50.0%" alt="Screening mammogram"> <!-- \begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{figures/mammogram.jpg}
\caption{Breast cancer screening mammogram. AI enhances diagnostic accuracy.}
\end{figure} --></p>
<p>According to recent research<span class="citation" data-cites="lee2017"><sup><a href="#ref-lee2017" role="doc-biblioref">1</a></sup></span>, neural networks outperform …</p>
</section>
<section id="objectives" class="level3">
<h3 class="anchored" data-anchor-id="objectives">1.2 Objectives</h3>
<ul>
<li>Apply deep learning (CNNs) to mammography image classification.</li>
<li>Evaluate performance vs.&nbsp;traditional methods/radiologists.</li>
</ul>
</section>
<section id="scope" class="level3">
<h3 class="anchored" data-anchor-id="scope">1.3 Scope</h3>
<p>Briefly note focus on classification (benign vs malignant), dataset used, and evaluation metrics.</p>
<p>Background &amp; Motivation</p>
<ul>
<li>Significance of early breast cancer detection.</li>
<li>NHS 2025 initiative on DL for screening.</li>
</ul>
<p>Project Objectives</p>
<ul>
<li>Build and evaluate CNN models using the DDSM/CBIS-DDSM dataset.</li>
<li>Assess whether CNNs can match or exceed radiologist performance.</li>
</ul>
<p>Scope</p>
<ul>
<li>Focus on classification (benign vs.&nbsp;malignant), with optional segmentation.</li>
<li>Use curated public data for transparency and reproducibility.</li>
</ul>
</section>
</section>
<section id="dataset" class="level2">
<h2 class="anchored" data-anchor-id="dataset">2. Dataset</h2>
<section id="dataset-description" class="level3">
<h3 class="anchored" data-anchor-id="dataset-description">2.1 Dataset Description</h3>
<ul>
<li>Dataset: CBIS-DDSM</li>
<li>Number of cases: 753 calcifications, 891 masses</li>
<li>Modalities: Mammograms with labels and ROI masks</li>
</ul>
</section>
<section id="preprocessing" class="level3">
<h3 class="anchored" data-anchor-id="preprocessing">2.2 Preprocessing</h3>
<ul>
<li>Resizing, normalization, augmentation</li>
<li>ROI extraction (if applied)</li>
</ul>
</section>
<section id="splitting-strategy" class="level3">
<h3 class="anchored" data-anchor-id="splitting-strategy">2.3 Splitting Strategy</h3>
<ul>
<li>Training, validation, and test set proportions</li>
<li>Use of predefined splits if applicable</li>
</ul>
<p>Dataset Description</p>
<ul>
<li>Use of CBIS-DDSM (Lee et al., 2017) — curated version of DDSM.</li>
<li>Number of images, classes (benign/malignant), calcifications vs.&nbsp;masses.</li>
</ul>
<p>Preprocessing Steps</p>
<ul>
<li>ROI extraction, resizing, normalization.</li>
<li>Augmentation techniques (flipping, rotation, etc.).</li>
</ul>
<p>Train/Validation/Test Split</p>
<ul>
<li>Based on BI-RADS or predefined splits from the dataset.</li>
</ul>
</section>
</section>
<section id="deep-learning-workflow" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-workflow">3. Deep Learning Workflow</h2>
<section id="problem-definition" class="level3">
<h3 class="anchored" data-anchor-id="problem-definition">3.1 Problem Definition</h3>
<p>Define input/output: - Input: X-ray mammogram or ROI - Output: Binary label (benign or malignant)</p>
<p>Define the supervised classification task: - Input: X-ray mammogram image (ROI or full view) - Output: Binary label (benign/malignant)</p>
</section>
<section id="data-preparation" class="level3">
<h3 class="anchored" data-anchor-id="data-preparation">3.2 Data Preparation</h3>
<ul>
<li>Preprocessing steps
<ul>
<li>Denoising, rescaling, grayscale conversion</li>
<li>Normalization [e.g., pixel range 0–1 or mean/std]</li>
</ul></li>
<li>Label encoding</li>
<li>Data augmentation techniques: flips, rotations, zooms</li>
</ul>
</section>
<section id="model-building" class="level3">
<h3 class="anchored" data-anchor-id="model-building">3.3 Model Building</h3>
<ul>
<li>Baseline model: custom CNN</li>
<li>Advanced models:
<ul>
<li>Transfer learning (e.g., VGG16, ResNet50)</li>
<li>Optional segmentation with U-Net</li>
</ul></li>
</ul>
</section>
<section id="model-training" class="level3">
<h3 class="anchored" data-anchor-id="model-training">3.4 Model Training</h3>
<ul>
<li>Loss function: Binary Crossentropy</li>
<li>Optimizer: Adam</li>
<li>Metrics: Accuracy, AUC, Sensitivity, Specificity, F1-score</li>
<li>Epochs, batch size, learning rate, early stopping, callbacks (e.g., early stopping, LR scheduler)</li>
</ul>
</section>
<section id="evaluation" class="level3">
<h3 class="anchored" data-anchor-id="evaluation">3.5 Evaluation</h3>
<ul>
<li>Report performance on test set
<ul>
<li>Confusion matrix</li>
<li>ROC curve, AUC</li>
<li>Precision, Recall, F1-score</li>
</ul></li>
</ul>
</section>
<section id="model-improvement" class="level3">
<h3 class="anchored" data-anchor-id="model-improvement">3.6 Model Improvement</h3>
<ul>
<li><p>Regularization techniques: dropout, L2</p></li>
<li><p>Data augmentation experiments</p></li>
<li><p>Architecture tuning: more layers, batch norm<br>
</p></li>
<li><p>Transfer learning comparisons</p></li>
<li><p>Add dropout / L2 regularization</p></li>
<li><p>Increase network depth</p></li>
<li><p>Apply transfer learning</p></li>
<li><p>Tune hyperparameters</p></li>
</ul>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">4. Results</h2>
<ul>
<li>Performance Tables: Accuracy, AUC, Sensitivity, Specificity per model</li>
<li>Visualizations: ROC curve, training/validation loss curves</li>
<li>Error Analysis: Misclassified cases, confusion matrix</li>
<li>Example visualizations of predictions (e.g., Grad-CAM)</li>
</ul>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">5. Discussion</h2>
<ul>
<li>Compare results with literature benchmarks
<ul>
<li>Comparison with Radiologists (Wang 2024)</li>
</ul></li>
<li>Strengths and limitations of the model/approach</li>
<li>Interpretability &amp; practical deployment considerations
<ul>
<li>Grad-CAM (optional)</li>
</ul></li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">6. Conclusion</h2>
<ul>
<li>Summary of findings</li>
<li>Implications for clinical use: Whether deep learning improves screening performance</li>
<li>Suggestions for future work: Recommendations for future research (ensemble models, multi-task learning)</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">7. References</h2>
<ul>
<li>Wang L. (2024). <em>Frontiers in Oncology</em></li>
<li>Lee et al.&nbsp;(2017). <em>Scientific Data</em></li>
<li>Chollet, F. (2018). <em>Deep Learning with Python</em></li>
<li>TensorFlow/Keras documentation</li>
</ul>
</section>
<section id="appendix" class="level2">
<h2 class="anchored" data-anchor-id="appendix">Appendix</h2>
<section id="a.-code-snippets" class="level3">
<h3 class="anchored" data-anchor-id="a.-code-snippets">A. Code Snippets</h3>
<ul>
<li>Add code snippets here later</li>
</ul>
</section>
<section id="b.-hyperparameter-table" class="level3">
<h3 class="anchored" data-anchor-id="b.-hyperparameter-table">B. Hyperparameter Table</h3>
<ul>
<li>Add hyperparameter tables</li>
</ul>
</section>
<section id="c.-full-model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="c.-full-model-architecture">C. Full Model Architecture</h3>
<ul>
<li>Add full model architecture</li>
</ul>
</section>
<section id="d.-data-statistics" class="level3">
<h3 class="anchored" data-anchor-id="d.-data-statistics">D. Data Statistics</h3>
<ul>
<li>Add any dataset distribution histograms or BI-RADS label breakdowns</li>
</ul>
</section>
<section id="e.-report-writing-tools" class="level3">
<h3 class="anchored" data-anchor-id="e.-report-writing-tools">E. Report Writing Tools</h3>
<p>The writing process for this report was conducted using <strong>Quarto</strong>, a modern scientific and technical publishing system that integrates <strong>Markdown</strong>, <strong>LaTeX</strong>, and executable code within a single framework. The project uses the <code>manuscript</code> type configuration to generate both <strong>PDF (via XeLaTeX)</strong> and <strong>HTML outputs</strong> with consistent styling, numbered sections, and title-cased tables of contents. The directory follows a modular structure (<code>_quarto.yml</code>, <code>report.qmd</code>), with customizations for fonts, TOC titles, and citation formatting via <code>.bib</code> and <code>.csl</code> files. <strong>Version control</strong> was managed using <strong>Git and GitHub</strong>, enabling reproducible and collaborative manuscript development. Integrated with <strong>VSCode</strong> and <strong>Zotero (via Better BibTeX)</strong>, this setup provides a complete academic writing workflow—featuring live previews, citation support, and source-controlled outputs—crucial for high-quality, reproducible scientific communication.</p>
</section>
</section>
<section id="references-1" class="level2 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body" data-entry-spacing="0" data-line-spacing="2" role="list">
<div id="ref-lee2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Lee, R. S. <em>et al.</em> <a href="https://doi.org/10.1038/sdata.2017.177">A curated mammography data set for use in computer-aided detection and diagnosis research</a>. <em>Scientific Data</em> <strong>4</strong>, 170177 (2017).</div>
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>