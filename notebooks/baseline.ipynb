{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972bf625",
   "metadata": {},
   "source": [
    "### Build TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d174e18",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y\n",
    "!python3 -m venv .venv\n",
    "!source .venv/bin/activate\n",
    "!pip install tensorflow==2.15.0\n",
    "!pip install pandas pydicom scikit-learn seaborn nbformat\n",
    "\n",
    "# The cuXXX (CUDA) wheels are Linux-only, NVIDIA GPU-only\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121/\n",
    "\n",
    "# Use the command from the PyTorch website for macOS!\n",
    "# !pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0e3ef8",
   "metadata": {},
   "source": [
    "#### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "019b84d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set TensorFlow logging level to suppress warnings\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4802d273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-09 05:50:01.582379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-09 05:50:01.582414: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-09 05:50:01.583686: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Num GPUs Available: 2\n",
      "GPU Devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import ast\n",
    "import pydicom\n",
    "\n",
    "#  Check TensorFlow version and GPU availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Global configuration\n",
    "INPUT_SHAPE = (224, 224, 1)  # (512, 512, 1)\n",
    "TARGET_SIZE = INPUT_SHAPE[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133a1a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA device count: 2\n",
      "Current device: 0\n",
      "Device name: NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch version and GPU availability\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "# Never use the cuXXX index for macOS!\n",
    "# Use the official PyPI source, or the command from the PyTorch website.\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b604807",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee38a64",
   "metadata": {},
   "source": [
    "These helper functions, stored in a separate file named `data_utils.py`, load and preprocess DICOM images and masks, parse dataset records, and build a TensorFlow dataset for multitask learning from a metadata CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114571a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICOM Loader\n",
    "def load_dicom_image(path_tensor):\n",
    "    \"\"\"\n",
    "    Loads and normalizes a DICOM image from a byte string path\n",
    "    Converts image pixel values to float32, scales them to [0, 1], and handles exceptions by returning a zero image.\n",
    "    \"\"\"\n",
    "    path = path_tensor.decode('utf-8')  # Decode byte string to UTF-8\n",
    "    try:\n",
    "        ds = pydicom.dcmread(path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        img -= np.min(img)\n",
    "        img /= (np.max(img) + 1e-6)  # normalize to [0,1]\n",
    "    except Exception as e:\n",
    "        print(f\"[DICOM ERROR] {path}: {e}\")\n",
    "        img = np.zeros(TARGET_SIZE, dtype=np.float32)\n",
    "    return img\n",
    "\n",
    "\n",
    "# TensorFlow Wrappers\n",
    "def tf_load_dicom(path):\n",
    "    \"\"\"\n",
    "    loads a single full mammogram DICOM image using load_dicom_image.\n",
    "    Ensures the image has shape (H, W, 1), resizes it to the target size, and returns it as a TensorFlow tensor.\n",
    "    \"\"\"\n",
    "    img = tf.numpy_function(func=load_dicom_image, inp=[path], Tout=tf.float32)\n",
    "    img.set_shape([None, None])  # initially 2D\n",
    "    img = tf.expand_dims(img, axis=-1)  # [H, W, 1]\n",
    "    img.set_shape([None, None, 1])\n",
    "    img = tf.image.resize(img, TARGET_SIZE)\n",
    "    return img\n",
    "\n",
    "\n",
    "def tf_load_multiple_dicom(paths):\n",
    "    \"\"\"\n",
    "    Loads and combines multiple DICOM mask images (e.g., for multiple ROIs).\n",
    "    Loads each mask, stacks them, and returns the pixel-wise union using tf.reduce_max.\n",
    "    \"\"\"\n",
    "    def load_single(path):\n",
    "        img = tf.numpy_function(load_dicom_image, [path], tf.float32)\n",
    "        img.set_shape([None, None])\n",
    "        img = tf.expand_dims(img, axis=-1)\n",
    "        img.set_shape([None, None, 1])\n",
    "        img = tf.image.resize(img, TARGET_SIZE)\n",
    "        return img\n",
    "\n",
    "    masks = tf.map_fn(\n",
    "        load_single,\n",
    "        paths,\n",
    "        fn_output_signature=tf.TensorSpec(shape=(TARGET_SIZE[0], TARGET_SIZE[1], 1), dtype=tf.float32)\n",
    "    )\n",
    "    return tf.reduce_max(masks, axis=0)  # union of all masks\n",
    "\n",
    "\n",
    "# Unified MTL Preprocessor for multitask learning (MTL)\n",
    "def load_and_preprocess(image_path, mask_paths, label):\n",
    "    \"\"\"\n",
    "    loads a single image, multiple mask images, and casts the label.\n",
    "    Returns a tuple: (image, {\"segmentation\": mask, \"classification\": label}).\n",
    "    \"\"\"\n",
    "    image = tf_load_dicom(image_path)\n",
    "    mask = tf_load_multiple_dicom(mask_paths)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, {\"segmentation\": mask, \"classification\": label}\n",
    "\n",
    "\n",
    "def parse_record(record):\n",
    "    \"\"\"\n",
    "    parses a dictionary record (with keys image_path, mask_paths, label) using load_and_preprocess.\n",
    "    \"\"\"\n",
    "    image_path = record['image_path']\n",
    "    mask_paths = record['mask_paths']\n",
    "    label = record['label']\n",
    "    image, target = load_and_preprocess(image_path, mask_paths, label)\n",
    "    return image, target\n",
    "\n",
    "\n",
    "# Builds a tf.data.Dataset from a metadata CSV file\n",
    "def build_tf_dataset(\n",
    "    metadata_csv: str,\n",
    "    batch_size: int = 8,\n",
    "    shuffle: bool = True\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Reads and parses the CSV, converts mask path strings to lists, ensures correct label type, and creates a TensorFlow dataset of records.\n",
    "    Applies the multitask mapping (parse_record), shuffles, batches, and prefetches.\n",
    "    \"\"\"\n",
    "    # Load metadata CSV\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "    # Parse stringified list of mask_paths\n",
    "    df['mask_paths'] = df['mask_paths'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "    # Ensure label column is float32-compatible (e.g., 0.0, 1.0)\n",
    "    df['label'] = df['label'].astype(np.float32)\n",
    "    # Convert to list of dicts\n",
    "    records = df[['image_path', 'mask_paths', 'label']].to_dict(orient='records')\n",
    "    # Create dataset\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: (r for r in records),\n",
    "        output_signature={\n",
    "            \"image_path\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            \"mask_paths\": tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
    "            \"label\": tf.TensorSpec(shape=(), dtype=tf.float32),\n",
    "        }\n",
    "    )\n",
    "    # Apply MTL-compatible mapping function\n",
    "    ds = ds.map(lambda r: parse_record(r), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(records))\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172103ee",
   "metadata": {},
   "source": [
    "The resulting `ds` is a complete TensorFlow dataset of `(image, {\"segmentation\": mask, \"classification\": label})` tuples—normalized, resized, shuffled, batched, and ready for model training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7dd35f",
   "metadata": {},
   "source": [
    "### Develop a Baseline Sequential CNN Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528dd6ae",
   "metadata": {},
   "source": [
    "Das et al. (2023) outline a flexible deep learning pipeline for breast cancer classification, featuring two main strategies: **Shallow CNN** and **Deep CNN**. Following their workflow, we first implement the shallow CNN approach as a baseline.\n",
    "\n",
    "We develop a simple CNN model with an encoder and classification head, using only convolutional, pooling, and fully connected layers for binary (or multiclass) classification. This baseline allows us to objectively assess future model improvements.\n",
    "\n",
    "The **Shallow CNN** path follows three incremental steps:\n",
    "\n",
    "* 2 Conv Layers (baseline)\n",
    "* 2 Conv Layers + Dropout\n",
    "* 2 Conv Layers + Dropout + Data Augmentation\n",
    "\n",
    "For each step, we use CBIS-DDSM dataset, apply standard preprocessing, and train the model, tuning hyperparameters as needed. Performance is evaluated with standard metrics, providing a foundation for deeper or more complex models in later experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b30c29",
   "metadata": {},
   "source": [
    "#### Set up Weights & Biases for experiment tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d5d7bf",
   "metadata": {},
   "source": [
    "To make experiment tracking easier, we first install [Weights & Biases (wandb)](https://wandb.ai/) for experiment management and visualization. This tool allows us to log metrics, visualize model performance, and organize experiments efficiently.\n",
    "```sh\n",
    "pip install wandb\n",
    "```\n",
    "For first-time setup, we need to log in to wandb by pasting an API key when prompted:\n",
    "```sh\n",
    "wandb login\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb04ef",
   "metadata": {},
   "source": [
    "### Part 1: CNN with 2 Convolutional Layers (baseline)\n",
    "  This baseline model consists of two convolutional layers followed by pooling, a dense layer, and an output layer. It serves as the simplest deep learning architecture in the pipeline and acts as a benchmark for evaluating further enhancements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f793f98",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163629a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set TensorFlow logging level to suppress warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "INPUT_SHAPE = (224, 224, 1)\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4\n",
    "MODEL_DIR = \"./models\"\n",
    "HISTORY_DIR = \"../results/history\"\n",
    "PROJECT = \"baseline_cnn_2_conv_layers\"\n",
    "LABELS = [\"BENIGN\", \"MALIGNANT\"]\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(HISTORY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "418c01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Ensure the models directory exists\n",
    "import os\n",
    "model_dir = os.path.abspath(\"../models\")\n",
    "os.makedirs(model_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad20c5a6",
   "metadata": {},
   "source": [
    "#### Build and compile a shallow CNN model as a baseline\n",
    "\n",
    "A shallow convolutional neural network (CNN) model was constructed and compiled using an appropriate loss function and optimizer. The model was then trained on the dataset, with training progress monitored using a validation set. Key performance metrics—including accuracy and loss—were evaluated on the validation set to assess the model’s baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6eeac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_shallow_cnn(input_shape=INPUT_SHAPE, num_classes=1):\n",
    "    return models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8881c6",
   "metadata": {},
   "source": [
    "#### Prepare Data and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2b3b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "metadata = pd.read_csv(\"../data/processed/cbis_ddsm_metadata_full.csv\")\n",
    "\n",
    "train_meta, val_meta = train_test_split(\n",
    "    metadata, test_size=0.2, stratify=metadata['label'], random_state=42\n",
    ")\n",
    "\n",
    "train_meta.to_csv(\"../temporary/train_split.csv\", index=False)\n",
    "val_meta.to_csv(\"../temporary/val_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c0b6b9",
   "metadata": {},
   "source": [
    "#### Build TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0bf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import build_tf_dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "train_ds = build_tf_dataset(metadata_csv=\"../temporary/train_split.csv\", batch_size=BATCH_SIZE)\n",
    "val_ds = build_tf_dataset(metadata_csv=\"../temporary/val_split.csv\", batch_size=BATCH_SIZE)\n",
    "train_ds = train_ds.map(lambda x, y: (x, y[\"classification\"])).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (x, y[\"classification\"])).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5af0a6",
   "metadata": {},
   "source": [
    "#### Compile and Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "143e3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = build_shallow_cnn(INPUT_SHAPE)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba31ff90",
   "metadata": {},
   "source": [
    "#### Initialize W&B and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c979d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtkshfj\u001b[0m (\u001b[33mtkshfj-bsc-computer-science-university-of-london\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/tkshfj/repository/MMG/notebooks/wandb/run-20250609_060018-auulx7la</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tkshfj-bsc-computer-science-university-of-london/baseline_cnn_2_conv_layers/runs/auulx7la' target=\"_blank\">devout-blaze-1</a></strong> to <a href='https://wandb.ai/tkshfj-bsc-computer-science-university-of-london/baseline_cnn_2_conv_layers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tkshfj-bsc-computer-science-university-of-london/baseline_cnn_2_conv_layers' target=\"_blank\">https://wandb.ai/tkshfj-bsc-computer-science-university-of-london/baseline_cnn_2_conv_layers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tkshfj-bsc-computer-science-university-of-london/baseline_cnn_2_conv_layers/runs/auulx7la' target=\"_blank\">https://wandb.ai/tkshfj-bsc-computer-science-university-of-london/baseline_cnn_2_conv_layers/runs/auulx7la</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using `save_best_only`, ensure that the `filepath` argument contains formatting placeholders like `{epoch:02d}` or `{batch:02d}`. This ensures correct interpretation of the logged artifacts.\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=PROJECT, config={\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"architecture\": \"shallow_cnn\"\n",
    "})\n",
    "\n",
    "callbacks = [\n",
    "    wandb.keras.WandbMetricsLogger(),\n",
    "    wandb.keras.WandbModelCheckpoint(\n",
    "        filepath=os.path.join(MODEL_DIR, \"best_model_epoch.keras\"),\n",
    "        monitor=\"val_loss\", save_best_only=True\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_loss\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f611cd",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd856274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 257s 134ms/step - loss: 0.6606 - accuracy: 0.6053 - auc: 0.6096 - precision: 0.5385 - recall: 0.2945 - val_loss: 0.6404 - val_accuracy: 0.6218 - val_auc: 0.6528 - val_precision: 0.5532 - val_recall: 0.4207\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 250s 130ms/step - loss: 0.6120 - accuracy: 0.6527 - auc: 0.7028 - precision: 0.6013 - recall: 0.4660 - val_loss: 0.6113 - val_accuracy: 0.6498 - val_auc: 0.7026 - val_precision: 0.5898 - val_recall: 0.4887\n",
      "Epoch 3/20\n",
      "369/375 [============================>.] - ETA: 0s - loss: 0.5556 - accuracy: 0.7016 - auc: 0.7748 - precision: 0.6744 - recall: 0.5281"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52a692",
   "metadata": {},
   "source": [
    "#### Save History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b560a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "hist_df = pd.DataFrame(history.history)\n",
    "hist_df.to_csv(os.path.join(HISTORY_DIR, \"baseline-cnn-2-conv-layers.csv\"), index=True)\n",
    "\n",
    "with open(os.path.join(HISTORY_DIR, \"baseline-cnn-2-conv-layers.pkl\"), 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2253dae9",
   "metadata": {},
   "source": [
    "#### Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7383dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history, metrics=('accuracy', 'auc', 'precision', 'recall')):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    for idx, metric in enumerate(metrics, 1):\n",
    "        plt.subplot(2, 2, idx)\n",
    "        plt.plot(history[metric], label='Train')\n",
    "        plt.plot(history['val_' + metric], label='Validation')\n",
    "        plt.title(metric.capitalize())\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric.capitalize())\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6aafc0",
   "metadata": {},
   "source": [
    "#### Compute and Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Gather all validation data and labels\n",
    "val_images, val_labels = [], []\n",
    "for imgs, labels in val_ds:\n",
    "    val_images.append(imgs.numpy())\n",
    "    val_labels.append(labels.numpy())\n",
    "val_images = np.concatenate(val_images, axis=0)\n",
    "val_labels = np.concatenate(val_labels, axis=0)\n",
    "\n",
    "# Model predictions\n",
    "y_prob = model.predict(val_images)\n",
    "y_pred = (y_prob > 0.5).astype(int).flatten()\n",
    "y_true = val_labels.flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520348b3",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d259c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(MODEL_DIR, \"baseline-cnn-2-conv-layers.keras\"))\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17370fb3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "895e74e7",
   "metadata": {},
   "source": [
    "### Part 2–3: CNN with Dropout & Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31ba52",
   "metadata": {},
   "source": [
    "In this section, we **combine two regularization strategies** for our baseline CNN:\n",
    "\n",
    "* **Dropout Layer:** Added after flattening, this layer randomly drops a fraction of features during training to help prevent overfitting.\n",
    "* **Data Augmentation Pipeline:** Integrated as a preprocessing layer, leveraging TensorFlow’s built-in augmentation operations (random flip, rotation, zoom, translation) to increase data diversity.\n",
    "\n",
    "**Key Implementation Details:**\n",
    "\n",
    "* The **dropout rate** and **augmentation parameters** (rotation, zoom, translation) are exposed as hyperparameters.\n",
    "* The entire model pipeline—including architecture, training, dropout, and augmentation—is implemented in a unified script (`train.py`), with all configuration handled via Weights & Biases (W\\&B) sweeps.\n",
    "* **All key hyperparameters**—including filter count, kernel size, dropout rate, batch size, learning rate, and augmentation strengths—are defined in `sweep.yaml` for systematic optimization.\n",
    "\n",
    "**Benefits of the Combined Approach:**\n",
    "\n",
    "* Enables robust evaluation of the impact of regularization and augmentation on model generalization.\n",
    "* Supports automated, reproducible hyperparameter search with Bayesian optimization using W\\&B sweeps.\n",
    "\n",
    "**Summary:**\n",
    "This improved codebase offers a modular and flexible setup where dropout and data augmentation are seamlessly integrated, supporting efficient experimentation and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a290e",
   "metadata": {},
   "source": [
    "To mitigate overfitting and improve the model’s ability to generalize, a Dropout layer is added after the dense layer. Dropout randomly deactivates a proportion of neurons during training, preventing the network from relying too heavily on specific features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f8b29",
   "metadata": {},
   "source": [
    "We use Weights and Biases Sweeps to automate hyperparameter search and model optimization. https://docs.wandb.ai/guides/sweeps/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c7a42",
   "metadata": {},
   "source": [
    "#### Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_utils import build_tf_dataset\n",
    "\n",
    "# Model input shape\n",
    "INPUT_SHAPE = (224, 224, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9160684b",
   "metadata": {},
   "source": [
    "#### Data Augmentation and Model Building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_augmentation(rotation=0.1, zoom=0.1, translation=0.1):\n",
    "    \"\"\"Return a Sequential data augmentation pipeline.\"\"\"\n",
    "    return tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(rotation),\n",
    "        layers.RandomZoom(zoom),\n",
    "        layers.RandomTranslation(translation, translation)\n",
    "    ], name=\"data_augmentation\")\n",
    "\n",
    "def build_model(input_shape, filters=32, kernel_size=3, dropout=0.3, \n",
    "                rotation=0.1, zoom=0.1, translation=0.1):\n",
    "    \"\"\"Build a 2-layer CNN with data augmentation and dropout.\"\"\"\n",
    "    data_augmentation = build_data_augmentation(rotation, zoom, translation)\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        data_augmentation,\n",
    "        layers.Conv2D(filters, kernel_size, activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(filters * 2, kernel_size, activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154faac",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51420c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata and split\n",
    "metadata = pd.read_csv(\"../data/processed/cbis_ddsm_metadata_full.csv\")\n",
    "train_meta, val_meta = train_test_split(\n",
    "    metadata, test_size=0.2, stratify=metadata['label'], random_state=42\n",
    ")\n",
    "\n",
    "# Optionally, save splits\n",
    "train_meta.to_csv(\"../temporary/train_split.csv\", index=False)\n",
    "val_meta.to_csv(\"../temporary/val_split.csv\", index=False)\n",
    "\n",
    "# Build TensorFlow datasets\n",
    "batch_size = 8  # Set your batch size here, or override with hyperparameter\n",
    "train_ds = build_tf_dataset(metadata_csv=\"../temporary/train_split.csv\", batch_size=batch_size)\n",
    "val_ds = build_tf_dataset(metadata_csv=\"../temporary/val_split.csv\", batch_size=batch_size)\n",
    "train_ds = train_ds.map(lambda x, y: (x, y[\"classification\"])).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (x, y[\"classification\"])).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43582dbc",
   "metadata": {},
   "source": [
    "#### Model Initialization and Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190af5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: set hyperparameters directly, or pull from sweep/config\n",
    "model = build_model(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    dropout=0.3,\n",
    "    rotation=0.1,\n",
    "    zoom=0.1,\n",
    "    translation=0.1\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d83d3c",
   "metadata": {},
   "source": [
    "#### W&B Initialization and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e68e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"baseline_cnn_dropout_augmentation\", config={\n",
    "    \"filters\": 32,\n",
    "    \"kernel_size\": 3,\n",
    "    \"dropout\": 0.3,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"rotation\": 0.1,\n",
    "    \"zoom\": 0.1,\n",
    "    \"translation\": 0.1,\n",
    "    \"epochs\": 20\n",
    "})\n",
    "\n",
    "callbacks = [\n",
    "    wandb.keras.WandbMetricsLogger(),\n",
    "    EarlyStopping(patience=5, monitor=\"val_loss\", restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7100016",
   "metadata": {},
   "source": [
    "#### sweep.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15a87b",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "program: train.py\n",
    "method: bayes\n",
    "metric:\n",
    "  name: val_auc\n",
    "  goal: maximize\n",
    "parameters:\n",
    "  learning_rate:\n",
    "    min: 0.00001\n",
    "    max: 0.001\n",
    "  batch_size:\n",
    "    values: [8, 16, 32]\n",
    "  filters:\n",
    "    values: [16, 32, 64]\n",
    "  kernel_size:\n",
    "    values: [3, 5]\n",
    "  dropout:\n",
    "    min: 0.0\n",
    "    max: 0.5\n",
    "  epochs:\n",
    "    value: 20\n",
    "  rotation:\n",
    "    min: 0.0\n",
    "    max: 0.2\n",
    "  zoom:\n",
    "    min: 0.0\n",
    "    max: 0.2\n",
    "  translation:\n",
    "    min: 0.0\n",
    "    max: 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b9233",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db9e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep runs using wandb agent\n",
    "config = wandb.config\n",
    "\n",
    "model = build_model(\n",
    "    input_shape=INPUT_SHAPE,\n",
    "    filters=config.filters,\n",
    "    kernel_size=config.kernel_size,\n",
    "    dropout=config.dropout,\n",
    "    rotation=config.rotation,\n",
    "    zoom=config.zoom,\n",
    "    translation=config.translation\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,  # Or use config['epochs']\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d9521f",
   "metadata": {},
   "source": [
    "#### Save Model and End W&B Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45087812",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/baseline_cnn_dropout_augmentation.keras\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f578f6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcaa42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "\n",
    "# Build a CNN model with 2 convolutional layers and dropout\n",
    "def build_model(input_shape, filters=32, kernel_size=3, dropout=0.3):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(filters, kernel_size, activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Conv2D(filters*2, kernel_size, activation='relu'),\n",
    "        layers.MaxPooling2D(2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Main training function\n",
    "def train():\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"baseline_cnn_dropout_augmentation\")\n",
    "    config = wandb.config\n",
    "\n",
    "    # Data loading\n",
    "    metadata = pd.read_csv(\"../data/processed/cbis_ddsm_metadata_full.csv\")\n",
    "    # Split\n",
    "    train_meta, val_meta = train_test_split(metadata, test_size=0.2, stratify=metadata['label'], random_state=42)\n",
    "    train_meta.to_csv(\"../temporary/train_split.csv\", index=False)\n",
    "    val_meta.to_csv(\"../temporary/val_split.csv\", index=False)\n",
    "    # Build datasets\n",
    "    train_ds = build_tf_dataset(metadata_csv=\"../temporary/train_split.csv\", batch_size=8)\n",
    "    val_ds = build_tf_dataset(metadata_csv=\"../temporary/val_split.csv\", batch_size=8)\n",
    "    train_ds = train_ds.map(lambda x, y: (x, y[\"classification\"])).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (x, y[\"classification\"])).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Build the model with sweep config values\n",
    "    model = build_model(\n",
    "        input_shape=(224, 224, 1),           # <-- replace with your true input shape\n",
    "        filters=config.filters,\n",
    "        kernel_size=config.kernel_size,\n",
    "        dropout=config.dropout\n",
    "    )\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                 tf.keras.metrics.Precision(name=\"precision\"),\n",
    "                 tf.keras.metrics.Recall(name=\"recall\")]\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=config.epochs,\n",
    "        batch_size=config.batch_size,\n",
    "        callbacks=[\n",
    "            wandb.keras.WandbMetricsLogger(),\n",
    "            EarlyStopping(patience=5, monitor=\"val_loss\", restore_best_weights=True)\n",
    "        ],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "# Sweep configuration (as a Python dict, or save as sweep.yaml)\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",  # or \"random\", \"grid\"\n",
    "    \"metric\": {\"name\": \"val_auc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\"min\": 1e-5, \"max\": 1e-3},\n",
    "        \"batch_size\": {\"values\": [8, 16, 32]},\n",
    "        \"filters\": {\"values\": [16, 32, 64]},\n",
    "        \"kernel_size\": {\"values\": [3, 5]},\n",
    "        \"dropout\": {\"min\": 0.0, \"max\": 0.5},\n",
    "        \"epochs\": {\"value\": 20}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Launch the sweep\n",
    "import wandb\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"baseline_cnn_dropout_augmentation\")\n",
    "wandb.agent(sweep_id, function=train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce59d5",
   "metadata": {},
   "source": [
    "### Analyze the results of the hyperparameter sweep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12fdcc",
   "metadata": {},
   "source": [
    "Download all runs from the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Initialize API and get all runs for the project\n",
    "PROJECT = \"tkshfj-bsc-computer-science-university-of-london/baseline_cnn_dropout_augmentation\"\n",
    "api = wandb.Api()\n",
    "runs = api.runs(PROJECT)\n",
    "\n",
    "print(f\"Found {len(runs)} runs.\")\n",
    "\n",
    "# 2. Build DataFrame with config and summary metrics\n",
    "records = []\n",
    "for run in runs:\n",
    "    row = dict(run.config)\n",
    "    for k, v in run.summary.items():\n",
    "        if not k.startswith('_'):\n",
    "            row[k] = v\n",
    "    row['run_id'] = run.id\n",
    "    row['run_name'] = run.name\n",
    "    records.append(row)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb62f38",
   "metadata": {},
   "source": [
    "Find the Best Run by Metric (e.g., epoch/val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32db2c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Find best run by 'epoch/val_auc'\n",
    "if 'epoch/val_auc' in df.columns:\n",
    "    best_idx = df['epoch/val_auc'].idxmax()\n",
    "    best_run = df.iloc[best_idx]\n",
    "    print(\"Best run name:\", best_run['run_name'])\n",
    "    print(\"Best run ID:\", best_run['run_id'])\n",
    "    print(\"Best run val_auc:\", best_run['epoch/val_auc'])\n",
    "\n",
    "    # 4. Build URL\n",
    "    url = f\"https://wandb.ai/{PROJECT}/runs/{best_run['run_id']}\"\n",
    "    print(\"Best run URL:\", url)\n",
    "else:\n",
    "    print(\"epoch/val_auc not found in DataFrame columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Get the best run's history for learning curve\n",
    "run = api.run(f\"{PROJECT}/runs/{best_run['run_id']}\")\n",
    "history = run.history()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history['epoch/epoch'], history['epoch/val_auc'], label='Val AUC')\n",
    "plt.plot(history['epoch/epoch'], history['epoch/accuracy'], label='Train Acc')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.title(f\"Learning Curve: {best_run['run_name']}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86a27b",
   "metadata": {},
   "source": [
    "#### Find the Best Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = df.sort_values(\"epoch/val_auc\", ascending=False).iloc[0]\n",
    "print(\"Best run config:\", best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b470b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = df['epoch/val_auc'].idxmax()\n",
    "best_run = df.iloc[best_idx]\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e51c7b",
   "metadata": {},
   "source": [
    "#### Analyze Hyperparameter Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86e79b",
   "metadata": {},
   "source": [
    "#### Automated Result Plotting: Hyperparameter vs. Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b999cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(df['epoch/learning_rate'], df['epoch/val_auc'])\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Validation AUC\")\n",
    "plt.title(\"Learning Rate vs. Val AUC\")\n",
    "plt.xscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecb7831",
   "metadata": {},
   "source": [
    "#### Parallel Coordinates Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "params = ['epoch/learning_rate', 'batch_size', 'filters', 'kernel_size', 'dropout']\n",
    "parallel_coordinates(df[params + ['epoch/val_auc']], class_column='epoch/val_auc')\n",
    "plt.title(\"Parallel Coordinates: Hyperparameters vs. Val AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652678c",
   "metadata": {},
   "source": [
    "#### Learning Curves (Best/All Runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: download and plot learning curves for the best run\n",
    "run = api.run(\"tkshfj-bsc-computer-science-university-of-london/baseline_cnn_dropout_augmentation/h6zl7pfq\")\n",
    "history = run.history()\n",
    "plt.plot(history['epoch/epoch'], history['epoch/val_auc'], label='Val AUC')\n",
    "plt.plot(history['epoch/epoch'], history['epoch/accuracy'], label='Train Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.title(\"Learning Curves (Best Run)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575de12e",
   "metadata": {},
   "source": [
    "### Part 3: CNN with 2 Conv Layers + Data Augmentation\n",
    "  Building on Part 2, data augmentation techniques are introduced during the training phase. Methods such as random rotations, translations, zooms, and horizontal flips are applied to the input images, artificially increasing the diversity of the training set and further reducing the risk of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01b265",
   "metadata": {},
   "source": [
    "We apply data augmentation to your data pipeline to enhance the model's robustness and generalization capabilities. This involves applying transformations such as random rotations, shifts, zooms, and flips to the training images, which helps the model learn invariant features and improves its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af035419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Example of setting up data augmentation for training data\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "#     rotation_range=15,\n",
    "#     width_shift_range=0.1,\n",
    "#     height_shift_range=0.1,\n",
    "#     shear_range=0.1,\n",
    "#     zoom_range=0.1,\n",
    "#     horizontal_flip=True,\n",
    "#     fill_mode='nearest'\n",
    "# )\n",
    "\n",
    "# # For validation/test, only rescale\n",
    "# val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# # Example:\n",
    "# # train_generator = train_datagen.flow_from_directory(\n",
    "# #     'data/train',\n",
    "# #     target_size=(224, 224),\n",
    "# #     batch_size=32,\n",
    "# #     class_mode='categorical',  # or 'binary'\n",
    "# #     color_mode='grayscale',    # if images are grayscale\n",
    "# # )\n",
    "\n",
    "# # Use the same model as Part 2 (with dropout)\n",
    "# model = build_shallow_cnn_dropout(input_shape=INPUT_SHAPE, num_classes=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
