{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f37b9ea",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39a0af",
   "metadata": {},
   "source": [
    "### Steps Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eab0da",
   "metadata": {},
   "source": [
    "Dataset Organization: Directory structure\n",
    "\n",
    "```plaintext\n",
    "data/raw/\n",
    "├── Calc-Test_P_00038_LEFT_CC/\n",
    "│   └── .../1-1.dcm         (full mammogram image)\n",
    "├── Calc-Test_P_00038_LEFT_CC_1/\n",
    "│   └── .../1-1.dcm, 1-2.dcm (ROI mask images)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50495537",
   "metadata": {},
   "source": [
    "1. Scan DICOM Files\n",
    "- Recursively scan all .dcm files from data/raw/. Separate into full mammogram images and ROI masks.\n",
    "- Input: data/raw/\n",
    "- Output: List of file paths (full_mammo, roi_masks)\n",
    "\n",
    "2. Extract Metadata from File Paths\n",
    "- Parse abnormality type (Calc/Mass), patient ID, laterality (LEFT/RIGHT), and view (CC/MLO) from DICOM folder names.\n",
    "- Input: file paths\n",
    "- Output: structured dictionary per DICOM\n",
    "\n",
    "3. Pair Images and Masks\n",
    "- Match each full mammogram image to its corresponding ROI mask images based on naming convention.\n",
    "- Input: lists from Step 1\n",
    "- Output: paired image-mask metadata\n",
    "\n",
    "4. Consolidate Clinical Metadata CSVs\n",
    "- Read clinical metadata (calc_case_description_\\*.csv, mass_case_description_\\*.csv) from data/metadata/ and merge into a single DataFrame.\n",
    "- Input: data/metadata/ CSV files\n",
    "- Output: consolidated clinical metadata\n",
    "\n",
    "5. Merge Image–Mask Metadata and Clinical Metadata\n",
    "- Combine extracted folder metadata and consolidated clinical CSV metadata using keys like patient_id, view, laterality, and abnormality_id.\n",
    "- Export the merged, fully consolidated metadata DataFrame to data/processed/cbis_ddsm_metadata_full.csv.\n",
    "- Input: outputs of Step 3 and Step 4\n",
    "- Output: cbis_ddsm_metadata_full.csv\n",
    "\n",
    "6. Build TensorFlow Dataset\n",
    "- Create a tf.data.Dataset that loads image-mask-label triples ready for deep learning model training. Includes preprocessing like resizing and normalization.\n",
    "- Input: final metadata CSV\n",
    "- Output: TensorFlow-ready dataset (train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa0065",
   "metadata": {},
   "source": [
    "### Scan DICOM Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff71383",
   "metadata": {},
   "source": [
    "- Recursively scan all .dcm files from `base_dir`.\n",
    "- Separate into full mammogram images and ROI mask images.\n",
    "\n",
    "- Args:\n",
    "  - base_dir (str): Root directory containing DICOM folders (e.g., \"data/raw/\").\n",
    "\n",
    "- Returns:\n",
    "  - dict: {\n",
    "    - \"full_mammo\": [list of full mammogram DICOM paths],\n",
    "    - \"roi_masks\": [list of ROI mask DICOM paths] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e234b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "def scan_dicom_files(base_dir: str) -> Dict[str, List[str]]:\n",
    "    base_path = Path(base_dir)\n",
    "    dicom_files = {\n",
    "        \"full_mammo\": [],\n",
    "        \"roi_masks\": [],\n",
    "    }\n",
    "\n",
    "    if not base_path.exists():\n",
    "        raise ValueError(f\"Provided base directory does not exist: {base_dir}\")\n",
    "\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".dcm\"):\n",
    "                file_path = Path(root) / file\n",
    "                lower_root = str(root).lower()\n",
    "\n",
    "                if \"full mammogram images\" in lower_root:\n",
    "                    dicom_files[\"full_mammo\"].append(str(file_path))\n",
    "                elif \"roi mask images\" in lower_root:\n",
    "                    dicom_files[\"roi_masks\"].append(str(file_path))\n",
    "\n",
    "    print(f\"[INFO] Found {len(dicom_files['full_mammo'])} full mammogram DICOMs.\")\n",
    "    print(f\"[INFO] Found {len(dicom_files['roi_masks'])} ROI mask DICOMs.\")\n",
    "\n",
    "    return dicom_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 3103 full mammogram DICOMs.\n",
      "[INFO] Found 7026 ROI mask DICOMs.\n",
      "\n",
      "Example full mammogram paths:\n",
      "../data/raw/Mass-Test_P_00066_LEFT_CC/10-04-2016-DDSM-NA-12982/1.000000-full mammogram images-25433/1-1.dcm\n",
      "../data/raw/Calc-Test_P_02176_RIGHT_MLO/08-29-2017-DDSM-NA-33174/1.000000-full mammogram images-82696/1-1.dcm\n",
      "../data/raw/Calc-Training_P_00418_LEFT_CC/08-07-2016-DDSM-NA-95820/1.000000-full mammogram images-43865/1-1.dcm\n",
      "\n",
      "Example ROI mask paths:\n",
      "../data/raw/Calc-Training_P_01205_RIGHT_MLO_1/09-06-2017-DDSM-NA-99604/1.000000-ROI mask images-30743/1-1.dcm\n",
      "../data/raw/Calc-Training_P_01205_RIGHT_MLO_1/09-06-2017-DDSM-NA-99604/1.000000-ROI mask images-30743/1-2.dcm\n",
      "../data/raw/Calc-Training_P_00778_LEFT_CC_1/09-06-2017-DDSM-NA-38576/1.000000-ROI mask images-63875/1-1.dcm\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../data/raw/\"\n",
    "dicom_paths = scan_dicom_files(base_dir)\n",
    "\n",
    "# Access full mammograms and ROI masks\n",
    "full_mammo_files = dicom_paths[\"full_mammo\"]\n",
    "roi_mask_files = dicom_paths[\"roi_masks\"]\n",
    "\n",
    "# Preview first few rows\n",
    "print(\"\\nExample full mammogram paths:\")\n",
    "for path in full_mammo_files[:3]:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nExample ROI mask paths:\")\n",
    "for path in roi_mask_files[:3]:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a13a9",
   "metadata": {},
   "source": [
    "### Extract Metadata from File Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe5ed3f",
   "metadata": {},
   "source": [
    "- Extracts abnormality type, patient ID, laterality, and view from CBIS-DDSM DICOM file path.\n",
    "\n",
    "- Args:\n",
    "  - path (str or Path): Full path to a DICOM file.\n",
    "\n",
    "- Returns:\n",
    "  - dict: { \n",
    "      - \"abnormality_type\": \"Calc\" or \"Mass\",\n",
    "      - \"patient_id\": \"00038\",\n",
    "      - \"laterality\": \"LEFT\" or \"RIGHT\",\n",
    "      - \"view\": \"CC\" or \"MLO\",\n",
    "      - \"path\": full file path (str) }\n",
    "  - If parsing fails, returns None for the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf41467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Union, Dict\n",
    "\n",
    "def extract_metadata_from_path(path: Union[str, Path]) -> Dict[str, Union[str, None]]:\n",
    "    \"\"\"\n",
    "    Extract abnormality type, patient ID, laterality, view from any DICOM path\n",
    "    by searching path parts for the folder name.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "\n",
    "    # Try to find the folder matching \"Calc-...\" or \"Mass-...\" with pattern\n",
    "    for part in path.parts:\n",
    "        pattern = r\"^(Calc|Mass)-(Test|Training)_P_(\\d+)_([A-Z]+)_(CC|MLO)\"\n",
    "        match = re.match(pattern, part)\n",
    "        if match:\n",
    "            abnormality_type, dataset_split, patient_id, laterality, view = match.groups()\n",
    "            return {\n",
    "                \"abnormality_type\": abnormality_type,\n",
    "                \"patient_id\": patient_id,\n",
    "                \"laterality\": laterality,\n",
    "                \"view\": view,\n",
    "                \"path\": str(path)\n",
    "            }\n",
    "    \n",
    "    # If no match found\n",
    "    return {\n",
    "        \"abnormality_type\": None,\n",
    "        \"patient_id\": None,\n",
    "        \"laterality\": None,\n",
    "        \"view\": None,\n",
    "        \"path\": str(path)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea629a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Metadata:\n",
      "abnormality_type: Calc\n",
      "patient_id: 00038\n",
      "laterality: LEFT\n",
      "view: CC\n",
      "path: ../data/raw/Calc-Test_P_00038_LEFT_CC/08-29-2017-DDSM-NA-96009/1.000000-full mammogram images-63992/1-1.dcm\n"
     ]
    }
   ],
   "source": [
    "dicom_path = \"../data/raw/Calc-Test_P_00038_LEFT_CC/08-29-2017-DDSM-NA-96009/1.000000-full mammogram images-63992/1-1.dcm\"\n",
    "\n",
    "metadata = extract_metadata_from_path(dicom_path)\n",
    "\n",
    "print(\"Extracted Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38f194",
   "metadata": {},
   "source": [
    "### Pair Images and Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc6756e",
   "metadata": {},
   "source": [
    "- Pairs full mammogram images with corresponding ROI mask images based on naming convention.\n",
    "\n",
    "- Args:\n",
    "  - full_mammo_paths (List[str]): List of full mammogram DICOM paths.\n",
    "  - roi_mask_paths (List[str]): List of ROI mask DICOM paths.\n",
    "\n",
    "- Returns:\n",
    "  - List[Dict[str, str]]: List of dictionaries with keys:\n",
    "    - abnormality_type\n",
    "    - patient_id\n",
    "    - laterality\n",
    "    - view\n",
    "    - image_path\n",
    "    - mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8950d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def get_base_key(path: str) -> str:\n",
    "    path = Path(path)\n",
    "\n",
    "    # Search for the correct part\n",
    "    for part in path.parts:\n",
    "        pattern = r\"^(Calc|Mass)-(Test|Training)_P_(\\d+)_([A-Z]+)_(CC|MLO)\"\n",
    "        match = re.match(pattern, part)\n",
    "        if match:\n",
    "            abnormality_type, dataset_split, patient_id, laterality, view = match.groups()\n",
    "            return f\"{abnormality_type}-Test_P_{patient_id}_{laterality}_{view}\"\n",
    "    \n",
    "    # If not found, fallback\n",
    "    return None\n",
    "\n",
    "\n",
    "def pair_images_and_masks(full_mammo_paths, roi_mask_paths):\n",
    "    grouped_masks = defaultdict(list)\n",
    "    \n",
    "    for mask_path in roi_mask_paths:\n",
    "        base_key = get_base_key(mask_path)\n",
    "        grouped_masks[base_key].append(str(mask_path))\n",
    "\n",
    "    paired_records = []\n",
    "\n",
    "    for image_path in full_mammo_paths:\n",
    "        metadata = extract_metadata_from_path(image_path)\n",
    "        base_key = get_base_key(image_path)\n",
    "        mask_list = grouped_masks.get(base_key, [])\n",
    "\n",
    "        record = metadata.copy()\n",
    "        record[\"image_path\"] = str(image_path)\n",
    "        record[\"mask_paths\"] = mask_list  # <== LIST of mask paths!\n",
    "        paired_records.append(record)\n",
    "\n",
    "    return paired_records\n",
    "\n",
    "# Extracts a base key like 'Calc-Test_P_00038_LEFT_CC' or 'Mass-Test_P_00123_RIGHT_MLO'\n",
    "# from a DICOM file path, ignoring mask/image folder suffixes.\n",
    "# Args:\n",
    "#     path (str): Full DICOM file path.\n",
    "# Returns:\n",
    "#     str: Standardized base key for pairing (patient_id + view + laterality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "364a0e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 3103 full mammogram DICOMs.\n",
      "[INFO] Found 7026 ROI mask DICOMs.\n",
      "  abnormality_type patient_id laterality view  \\\n",
      "0             Mass      00066       LEFT   CC   \n",
      "1             Calc      02176      RIGHT  MLO   \n",
      "2             Calc      00418       LEFT   CC   \n",
      "3             Mass      01307      RIGHT  MLO   \n",
      "4             Mass      00488       LEFT   CC   \n",
      "\n",
      "                                                path  \\\n",
      "0  ../data/raw/Mass-Test_P_00066_LEFT_CC/10-04-20...   \n",
      "1  ../data/raw/Calc-Test_P_02176_RIGHT_MLO/08-29-...   \n",
      "2  ../data/raw/Calc-Training_P_00418_LEFT_CC/08-0...   \n",
      "3  ../data/raw/Mass-Test_P_01307_RIGHT_MLO/10-04-...   \n",
      "4  ../data/raw/Mass-Training_P_00488_LEFT_CC/07-2...   \n",
      "\n",
      "                                          image_path  \\\n",
      "0  ../data/raw/Mass-Test_P_00066_LEFT_CC/10-04-20...   \n",
      "1  ../data/raw/Calc-Test_P_02176_RIGHT_MLO/08-29-...   \n",
      "2  ../data/raw/Calc-Training_P_00418_LEFT_CC/08-0...   \n",
      "3  ../data/raw/Mass-Test_P_01307_RIGHT_MLO/10-04-...   \n",
      "4  ../data/raw/Mass-Training_P_00488_LEFT_CC/07-2...   \n",
      "\n",
      "                                          mask_paths  \n",
      "0  [../data/raw/Mass-Test_P_00066_LEFT_CC_1/10-04...  \n",
      "1  [../data/raw/Calc-Test_P_02176_RIGHT_MLO_1/08-...  \n",
      "2  [../data/raw/Calc-Training_P_00418_LEFT_CC_1/0...  \n",
      "3  [../data/raw/Mass-Test_P_01307_RIGHT_MLO_1/10-...  \n",
      "4  [../data/raw/Mass-Training_P_00488_LEFT_CC_1/0...  \n"
     ]
    }
   ],
   "source": [
    "# from scan_dicom_files import scan_dicom_files\n",
    "\n",
    "dicom_files = scan_dicom_files(\"../data/raw/\")\n",
    "\n",
    "full_mammo_paths = dicom_files[\"full_mammo\"]\n",
    "roi_mask_paths = dicom_files[\"roi_masks\"]\n",
    "\n",
    "paired_metadata = pair_images_and_masks(full_mammo_paths, roi_mask_paths)\n",
    "\n",
    "# Convert to DataFrame and preview\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(paired_metadata)\n",
    "print(df.head())\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df.to_csv(\"../data/processed/cbis_ddsm_metadata_paired.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e220975",
   "metadata": {},
   "source": [
    "### Consolidate Clinical Metadata CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb88faec",
   "metadata": {},
   "source": [
    "The four separately provided CBIS-DDSM metadata CSV files contain critical clinical information—such as BI-RADS category, pathology, assessment, and lesion subtlety—that are not embedded in the DICOM files or their folder names.\n",
    "\n",
    "- data/metadata/calc_case_description_test_set.csv\n",
    "- data/metadata/calc_case_description_train_set.csv\n",
    "- data/metadata/mass_case_description_test_set.csv\n",
    "- data/metadata/mass_case_description_train_set.csv\n",
    "\n",
    "Each rows contains the following columns:\n",
    "\n",
    "- Patient ID: `P_00038` — Unique patient identifier.\n",
    "- Breast Side: `LEFT` — Left breast.\n",
    "- Image View: `CC` or `MLO` — Standard cranio-caudal or mediolateral oblique view used in mammography.\n",
    "- Breast Density: `2`\n",
    "- Abnormality ID: `1`\n",
    "- Abnormality Type: `calcification` — Specifically dealing with microcalcifications.\n",
    "- Calcification Type: `PUNCTATE-PLEOMORPHIC` — Mixed types, suggesting variable morphology.\n",
    "- Calcification Distribution: `CLUSTERED` — Clustered microcalcifications, often suspicious.\n",
    "- Assessment: `4` — BI-RADS 4, suspicious abnormality; biopsy usually recommended.\n",
    "- Pathology: `BENIGN` — Biopsy/pathology confirmed the finding as benign.\n",
    "- Subtlety: `2` — Fairly subtle (1 = very subtle, 5 = very obvious).\n",
    "- Image Files:\n",
    "  - Original Image Path: Full mammogram DICOM.\n",
    "    Calc-Test_P_00038_LEFT_CC/1.3.6.1.4.1.9590.100.1.2.85935434310203356712688695661986996009/1.3.6.1.4.1.9590.100.1.2.374115997511889073021386151921807063992/000000.dcm\n",
    "  - Cropped Image Path: Focused region where calcifications are.\n",
    "    Calc-Test_P_00038_LEFT_CC_1/1.3.6.1.4.1.9590.100.1.2.161465562211359959230647609981488894942/1.3.6.1.4.1.9590.100.1.2.419081637812053404913157930753972718515/000001.dcm\n",
    "  - ROI Mask Path: Binary mask of the calcifications (region of interest).\n",
    "    Calc-Test_P_00038_LEFT_CC_1/1.3.6.1.4.1.9590.100.1.2.161465562211359959230647609981488894942/1.3.6.1.4.1.9590.100.1.2.419081637812053404913157930753972718515/000000.dcm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46957c",
   "metadata": {},
   "source": [
    "The following script reads and merges the metadata CSV files, cleans weird paths, adds missing fields where needed and exports everything into a properly formatted metadata_master.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d880bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master metadata CSV created: ../data/metadata/metadata_master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "# Input CSV files\n",
    "input_files = [\n",
    "    '../data/metadata/calc_case_description_test_set.csv',\n",
    "    '../data/metadata/calc_case_description_train_set.csv',\n",
    "    '../data/metadata/mass_case_description_test_set.csv',\n",
    "    '../data/metadata/mass_case_description_train_set.csv'\n",
    "]\n",
    "\n",
    "# Read CSVs by properly handling malformed newlines and all the data cleanly kept.\n",
    "dfs = []\n",
    "for file in input_files:\n",
    "    df = pd.read_csv(\n",
    "        file,\n",
    "        engine=\"python\",        # Use Python engine to properly handle malformed newlines\n",
    "        quoting=csv.QUOTE_MINIMAL, # Respect quotes\n",
    "        skip_blank_lines=True   # Optional: Skip totally blank lines\n",
    "    )\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all together\n",
    "metadata = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "metadata = metadata.rename(columns={\n",
    "    'patient_id': 'patient_id',\n",
    "    'left or right breast': 'side',\n",
    "    'image view': 'view',\n",
    "    'abnormality id': 'abnormality_id',\n",
    "    'abnormality type': 'abnormality_type',\n",
    "    'calc type': 'calc_type',\n",
    "    'calc distribution': 'distribution',\n",
    "    'mass shape': 'mass_shape',\n",
    "    'mass margins': 'mass_margins',\n",
    "    'breast density': 'breast_density',\n",
    "    'assessment': 'assessment',\n",
    "    'pathology': 'pathology',\n",
    "    'subtlety': 'subtlety',\n",
    "    'image file path': 'full_mammo_path',\n",
    "    'cropped image file path': 'cropped_roi_path',\n",
    "    'ROI mask file path': 'roi_mask_path'\n",
    "})\n",
    "\n",
    "# Add missing columns if needed\n",
    "for col in ['calc_type', 'distribution', 'mass_shape', 'mass_margins']:\n",
    "    if col not in metadata.columns:\n",
    "        metadata[col] = pd.NA\n",
    "\n",
    "# Normalize file paths\n",
    "def fix_path(path):\n",
    "    if pd.isna(path):\n",
    "        return None\n",
    "    # Remove a newline character embedded inside the \"cropped image file path\" field.\n",
    "    path = path.strip().replace('\\\\', '/').replace('\\\"', '')\n",
    "    parts = Path(path).parts\n",
    "    if len(parts) < 4:\n",
    "        return path\n",
    "    parent_folder = parts[0]\n",
    "    subfolder = parts[1]\n",
    "    file_name = parts[-1]\n",
    "    return f'raw/{parent_folder}/{subfolder}/{file_name}'\n",
    "\n",
    "# Apply path fixing\n",
    "for col in ['full_mammo_path', 'cropped_roi_path', 'roi_mask_path']:\n",
    "    metadata[col] = metadata[col].apply(fix_path)\n",
    "\n",
    "# Select final columns\n",
    "final_cols = [\n",
    "    'patient_id', 'breast_density', 'side', 'view', 'abnormality_id',\n",
    "    'abnormality_type', 'calc_type', 'distribution', 'mass_shape', 'mass_margins',\n",
    "    'assessment', 'pathology', 'subtlety',\n",
    "    'full_mammo_path', 'cropped_roi_path', 'roi_mask_path'\n",
    "]\n",
    "metadata = metadata[final_cols]\n",
    "\n",
    "# Save to CSV\n",
    "output_path = '../data/metadata/metadata_master.csv'\n",
    "metadata.to_csv(output_path, index=False)\n",
    "print(f'Master metadata CSV created: {output_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5585c02",
   "metadata": {},
   "source": [
    "### Merge Image–Mask Metadata and Clinical Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df934b",
   "metadata": {},
   "source": [
    "- Merge paired image–mask metadata with clinical metadata based on patient_id, view, laterality, and abnormality_id.\n",
    "\n",
    "- Args:\n",
    "  - paired_metadata_path (str): Path to the paired image-mask metadata CSV.\n",
    "  - clinical_metadata_path (str): Path to the consolidated clinical metadata CSV.\n",
    "  - output_path (str): Path to save the merged master metadata CSV.\n",
    "\n",
    "- Returns:\n",
    "  - pd.DataFrame: Final merged metadata DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee53a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_metadata(\n",
    "    paired_metadata_path: str,\n",
    "    clinical_metadata_path: str,\n",
    "    output_path: str\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    # Load CSVs\n",
    "    paired_df = pd.read_csv(paired_metadata_path)\n",
    "    clinical_df = pd.read_csv(clinical_metadata_path)\n",
    "\n",
    "    # Normalize column names if needed\n",
    "    paired_df = paired_df.rename(columns={\n",
    "        'side': 'laterality'  # If needed (depending on how it was named)\n",
    "    })\n",
    "\n",
    "    # Remove 'P_' prefix from clinical metadata patient IDs\n",
    "    clinical_df['patient_id'] = clinical_df['patient_id'].astype(str).str.replace('P_', '').str.zfill(5)\n",
    "\n",
    "    # Paired metadata: ensure patient_id is 5-digit zero-padded string\n",
    "    paired_df['patient_id'] = paired_df['patient_id'].astype(str).str.zfill(5)\n",
    "\n",
    "    # Ensure consistent casing for joining keys\n",
    "    paired_df['laterality'] = paired_df['laterality'].astype(str).str.upper()\n",
    "    paired_df['view'] = paired_df['view'].astype(str).str.upper()\n",
    "    clinical_df['side'] = clinical_df['side'].astype(str).str.upper()\n",
    "    clinical_df['view'] = clinical_df['view'].astype(str).str.upper()\n",
    "\n",
    "    # Merge: LEFT JOIN, keep all paired image/mask metadata\n",
    "    merged = pd.merge(\n",
    "        paired_df,\n",
    "        clinical_df,\n",
    "        how=\"left\",\n",
    "        left_on=[\"patient_id\", \"laterality\", \"view\"],\n",
    "        right_on=[\"patient_id\", \"side\", \"view\"]\n",
    "    )\n",
    "\n",
    "    # Drop duplicate columns (like \"side\" from clinical metadata)\n",
    "    if \"side\" in merged.columns:\n",
    "        merged = merged.drop(columns=[\"side\"])\n",
    "\n",
    "    # Save merged DataFrame\n",
    "    output_dir = Path(output_path).parent\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    merged.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"[INFO] Master merged metadata saved at: {output_path}\")\n",
    "    print(f\"[INFO] Merged metadata shape: {merged.shape}\")\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac9addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Master merged metadata saved at: ../data/processed/cbis_ddsm_metadata_full.csv\n",
      "[INFO] Merged metadata shape: (3751, 21)\n",
      "  abnormality_type_x patient_id laterality view  \\\n",
      "0               Mass      00066       LEFT   CC   \n",
      "1               Calc      02176      RIGHT  MLO   \n",
      "2               Calc      00418       LEFT   CC   \n",
      "3               Mass      01307      RIGHT  MLO   \n",
      "4               Mass      00488       LEFT   CC   \n",
      "\n",
      "                                                path  \\\n",
      "0  ../data/raw/Mass-Test_P_00066_LEFT_CC/10-04-20...   \n",
      "1  ../data/raw/Calc-Test_P_02176_RIGHT_MLO/08-29-...   \n",
      "2  ../data/raw/Calc-Training_P_00418_LEFT_CC/08-0...   \n",
      "3  ../data/raw/Mass-Test_P_01307_RIGHT_MLO/10-04-...   \n",
      "4  ../data/raw/Mass-Training_P_00488_LEFT_CC/07-2...   \n",
      "\n",
      "                                          image_path  \\\n",
      "0  ../data/raw/Mass-Test_P_00066_LEFT_CC/10-04-20...   \n",
      "1  ../data/raw/Calc-Test_P_02176_RIGHT_MLO/08-29-...   \n",
      "2  ../data/raw/Calc-Training_P_00418_LEFT_CC/08-0...   \n",
      "3  ../data/raw/Mass-Test_P_01307_RIGHT_MLO/10-04-...   \n",
      "4  ../data/raw/Mass-Training_P_00488_LEFT_CC/07-2...   \n",
      "\n",
      "                                          mask_paths  breast_density  \\\n",
      "0  ['../data/raw/Mass-Test_P_00066_LEFT_CC_1/10-0...             NaN   \n",
      "1  ['../data/raw/Calc-Test_P_02176_RIGHT_MLO_1/08...             4.0   \n",
      "2  ['../data/raw/Calc-Training_P_00418_LEFT_CC_1/...             3.0   \n",
      "3  ['../data/raw/Mass-Test_P_01307_RIGHT_MLO_1/10...             NaN   \n",
      "4  ['../data/raw/Mass-Training_P_00488_LEFT_CC_1/...             NaN   \n",
      "\n",
      "   breast_density.1  abnormality_id  ...              calc_type distribution  \\\n",
      "0               4.0               1  ...                    NaN          NaN   \n",
      "1               NaN               1  ...  AMORPHOUS-PLEOMORPHIC     REGIONAL   \n",
      "2               NaN               1  ...            PLEOMORPHIC    CLUSTERED   \n",
      "3               3.0               1  ...                    NaN          NaN   \n",
      "4               4.0               1  ...                    NaN          NaN   \n",
      "\n",
      "  mass_shape            mass_margins assessment  pathology subtlety  \\\n",
      "0  IRREGULAR              SPICULATED          4  MALIGNANT        3   \n",
      "1        NaN                     NaN          5  MALIGNANT        5   \n",
      "2        NaN                     NaN          4  MALIGNANT        2   \n",
      "3      ROUND           CIRCUMSCRIBED          3     BENIGN        5   \n",
      "4  IRREGULAR  CIRCUMSCRIBED-OBSCURED          4     BENIGN        3   \n",
      "\n",
      "                                     full_mammo_path  \\\n",
      "0  raw/Mass-Test_P_00066_LEFT_CC/1.3.6.1.4.1.9590...   \n",
      "1  raw/Calc-Test_P_02176_RIGHT_MLO/1.3.6.1.4.1.95...   \n",
      "2  raw/Calc-Training_P_00418_LEFT_CC/1.3.6.1.4.1....   \n",
      "3  raw/Mass-Test_P_01307_RIGHT_MLO/1.3.6.1.4.1.95...   \n",
      "4  raw/Mass-Training_P_00488_LEFT_CC/1.3.6.1.4.1....   \n",
      "\n",
      "                                    cropped_roi_path  \\\n",
      "0  raw/Mass-Test_P_00066_LEFT_CC_1/1.3.6.1.4.1.95...   \n",
      "1  raw/Calc-Test_P_02176_RIGHT_MLO_1/1.3.6.1.4.1....   \n",
      "2  raw/Calc-Training_P_00418_LEFT_CC_1/1.3.6.1.4....   \n",
      "3  raw/Mass-Test_P_01307_RIGHT_MLO_1/1.3.6.1.4.1....   \n",
      "4  raw/Mass-Training_P_00488_LEFT_CC_1/1.3.6.1.4....   \n",
      "\n",
      "                                       roi_mask_path  \n",
      "0  raw/Mass-Test_P_00066_LEFT_CC_1/1.3.6.1.4.1.95...  \n",
      "1  raw/Calc-Test_P_02176_RIGHT_MLO_1/1.3.6.1.4.1....  \n",
      "2  raw/Calc-Training_P_00418_LEFT_CC_1/1.3.6.1.4....  \n",
      "3  raw/Mass-Test_P_01307_RIGHT_MLO_1/1.3.6.1.4.1....  \n",
      "4  raw/Mass-Training_P_00488_LEFT_CC_1/1.3.6.1.4....  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "paired_metadata_path = \"../data/processed/cbis_ddsm_metadata_paired.csv\"\n",
    "clinical_metadata_path = \"../data/metadata/metadata_master.csv\"\n",
    "output_path = \"../data/processed/cbis_ddsm_metadata_full.csv\"\n",
    "merged_metadata = merge_metadata(paired_metadata_path, clinical_metadata_path, output_path)\n",
    "\n",
    "# Preview\n",
    "print(merged_metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef5f59f",
   "metadata": {},
   "source": [
    "### Build TensorFlow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f8e028b",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pip uninstall tensorflow -y\n",
    "# python3 -m venv .venv\n",
    "# source .venv/bin/activate\n",
    "# pip install tensorflow==2.15.0\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# pip install pandas pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebad51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce95c270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 21:30:27.080448: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-27 21:30:27.080482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-27 21:30:27.081650: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.0\n",
      "Num GPUs Available: 2\n",
      "GPU Devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c966529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA device count: 2\n",
      "Current device: 0\n",
      "Device name: NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22fe0dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: (8, 512, 512, 1)\n",
      "Masks batch shape: (8, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from pathlib import Path\n",
    "import ast\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = (512, 512)  # Resize target size\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_dicom_image(path_tensor):\n",
    "    \"\"\"\n",
    "    Load and normalize a DICOM image from a byte string path.\n",
    "    \"\"\"\n",
    "    path = path_tensor.decode('utf-8')  # Decode byte string to UTF-8\n",
    "    try:\n",
    "        ds = pydicom.dcmread(path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        img -= np.min(img)\n",
    "        img /= (np.max(img) + 1e-6)  # normalize to [0,1]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load DICOM file: {path} with error: {e}\")\n",
    "        img = np.zeros((512, 512), dtype=np.float32)  # or some fallback\n",
    "    return img\n",
    "\n",
    "def load_and_preprocess_image(image_path: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Load and preprocess a single full mammogram image.\n",
    "    \"\"\"\n",
    "    img = tf.numpy_function(load_dicom_image, [image_path], tf.float32)\n",
    "    img.set_shape([None, None])  # 2D\n",
    "    img = tf.expand_dims(img, axis=-1)  # Make it [H, W, 1]\n",
    "    img.set_shape([None, None, 1])\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return img\n",
    "\n",
    "def load_and_preprocess_mask(mask_paths: tf.Tensor) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Load and preprocess multiple ROI masks and combine into a single mask tensor.\n",
    "    \"\"\"\n",
    "    def load_single_mask(path):\n",
    "        mask = tf.numpy_function(load_dicom_image, [path], tf.float32)\n",
    "        mask.set_shape([None, None])\n",
    "        mask = tf.expand_dims(mask, axis=-1)\n",
    "        mask.set_shape([None, None, 1])\n",
    "        mask = tf.image.resize(mask, IMG_SIZE)\n",
    "        return mask\n",
    "\n",
    "    masks = tf.map_fn(\n",
    "        load_single_mask,\n",
    "        mask_paths,\n",
    "        fn_output_signature=tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 1), dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "    # Combine multiple masks into a single one\n",
    "    combined_mask = tf.reduce_max(masks, axis=0)\n",
    "    return combined_mask\n",
    "\n",
    "def parse_record(record):\n",
    "    \"\"\"\n",
    "    Parse a dictionary record into (image, mask) tensors.\n",
    "    \"\"\"\n",
    "    image_path = record['image_path']\n",
    "    mask_paths = record['mask_paths']\n",
    "\n",
    "    img = load_and_preprocess_image(image_path)\n",
    "    mask = load_and_preprocess_mask(mask_paths)\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "# --- Main Dataset Builder ---\n",
    "\n",
    "def build_tf_dataset(\n",
    "    metadata_csv: str,\n",
    "    batch_size: int = 8,\n",
    "    shuffle: bool = True\n",
    ") -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Build tf.data.Dataset from cbis_ddsm_metadata_full.csv\n",
    "    \"\"\"\n",
    "    # Load metadata\n",
    "    df = pd.read_csv(metadata_csv)\n",
    "\n",
    "    # Parse stringified list of mask_paths\n",
    "    df['mask_paths'] = df['mask_paths'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else [])\n",
    "\n",
    "    # Convert dataframe to list of dicts\n",
    "    records = df[['image_path', 'mask_paths']].to_dict(orient='records')\n",
    "\n",
    "    # Build tf.data.Dataset\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: (r for r in records),\n",
    "        output_signature={\n",
    "            \"image_path\": tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            \"mask_paths\": tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ds = ds.map(lambda r: parse_record(r), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(records))\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "# Build dataset\n",
    "train_ds = build_tf_dataset(\n",
    "    metadata_csv=\"../data/processed/cbis_ddsm_metadata_full.csv\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Preview one batch\n",
    "for images, masks in train_ds.take(1):\n",
    "    print(f\"Images batch shape: {images.shape}\")  # (8, 512, 512, 1)\n",
    "    print(f\"Masks batch shape: {masks.shape}\")    # (8, 512, 512, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df0983",
   "metadata": {},
   "source": [
    "The resulting train_ds is a complete TensorFlow training dataset — images and masks, normalized, resized, shuffled, batched, ready for model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
