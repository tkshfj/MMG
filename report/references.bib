@article{das2023,
  title = {Breast Cancer Detection: {{Shallow}} Convolutional Neural Network against Deep Convolutional Neural Networks Based Approach},
  shorttitle = {Breast Cancer Detection},
  author = {Das, Himanish Shekhar and Das, Akalpita and Neog, Anupal and Mallik, Saurav and Bora, Kangkana and Zhao, Zhongming},
  year = {2023},
  month = jan,
  journal = {Frontiers in Genetics},
  volume = {13},
  pages = {1097207},
  issn = {1664-8021},
  doi = {10.3389/fgene.2022.1097207},
  urldate = {2025-04-20},
  abstract = {Introduction:               Of all the cancers that afflict women, breast cancer (BC) has the second-highest mortality rate, and it is also believed to be the primary cause of the high death rate. Breast cancer is the most common cancer that affects women globally. There are two types of breast tumors: benign (less harmful and unlikely to become breast cancer) and malignant (which are very dangerous and might result in aberrant cells that could result in cancer).                                         Methods:               To find breast abnormalities like masses and micro-calcifications, competent and educated radiologists often examine mammographic images. This study focuses on computer-aided diagnosis to help radiologists make more precise diagnoses of breast cancer. This study aims to compare and examine the performance of the proposed shallow convolutional neural network architecture having different specifications against pre-trained deep convolutional neural network architectures trained on mammography images. Mammogram images are pre-processed in this study's initial attempt to carry out the automatic identification of BC. Thereafter, three different types of shallow convolutional neural networks with representational differences are then fed with the resulting data. In the second method, transfer learning via fine-tuning is used to feed the same collection of images into pre-trained convolutional neural networks VGG19, ResNet50, MobileNet-v2, Inception-v3, Xception, and Inception-ResNet-v2.                                         Results:               In our experiment with two datasets, the accuracy for the CBIS-DDSM and INbreast datasets are 80.4\%, 89.2\%, and 87.8\%, 95.1\% respectively.                                         Discussion:               It can be concluded from the experimental findings that the deep network-based approach with precise tuning outperforms all other state-of-the-art techniques in experiments on both datasets.},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/EKQ4STTE/Das et al. - 2023 - Breast cancer detection Shallow convolutional neural network against deep convolutional neural netw.pdf}
}

@article{el-banby2024,
  title = {Automated Abnormalities Detection in Mammography Using Deep Learning},
  author = {{El-Banby}, Ghada M. and Salem, Nourhan S. and Tafweek, Eman A. and {El-Azziz}, Essam N. Abd},
  year = {2024},
  month = oct,
  journal = {Complex \& Intelligent Systems},
  volume = {10},
  number = {5},
  pages = {7279--7295},
  issn = {2199-4536, 2198-6053},
  doi = {10.1007/s40747-024-01532-x},
  urldate = {2025-04-20},
  abstract = {Breast cancer is the second most prevalent cause of cancer death and the most common malignancy among women, posing a life-threatening risk. Treatment for breast cancer can be highly effective, with a survival chance of 90\% or higher, especially when the disease is detected early. This paper introduces a groundbreaking deep U-Net framework for mammography breast cancer images to perform automatic detection of abnormalities. The objective is to provide segmented images that show areas of tumors more accurately than other deep learning techniques. The proposed framework consists of three steps. The first step is image preprocessing using the Li algorithm to minimize the cross-entropy between the foreground and the background, contrast enhancement using contrast-limited adaptive histogram equalization (CLAHE), normalization, and median filtering. The second step involves data augmentation to mitigate overfitting and underfitting, and the final step is implementing a convolutional encoder-decoder network-based U-Net architecture, characterized by high precision in medical image analysis. The framework has been tested on two comprehensive public datasets, namely INbreast and CBIS-DDSM. Several metrics have been adopted for quantitative performance assessment, including the Dice score, sensitivity, Hausdorff distance, Jaccard coefficient, precision, and F1 score. Quantitative results on the INbreast dataset show an average Dice score of 85.61\% and a sensitivity of 81.26\%. On the CBIS-DDSM dataset, the average Dice score is 87.98\%, and the sensitivity reaches 90.58\%. The experimental results ensure earlier and more accurate abnormality detection. Furthermore, the success of the proposed deep learning framework in mammography shows promise for broader applications in medical imaging, potentially revolutionizing various radiological practices.},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/XDELERPS/El-Banby et al. - 2024 - Automated abnormalities detection in mammography using deep learning.pdf}
}

@misc{gov.uk2025,
  title = {World-Leading {{AI}} Trial to Tackle Breast Cancer Launched},
  author = {{gov.uk}},
  year = {2025},
  month = feb,
  journal = {Press release},
  urldate = {2025-04-16}
}

@article{hemali2023,
  title = {Mammogram {{Pre-processing Using}} Filtering Methods for {{Breast Cancer Diagnosis}}},
  author = {Hemali, Shah and Smita, Agrawal and Oza, Parita and Tanwar, Sudeep and Alkhayyat, Ahmed},
  year = {2023},
  month = aug,
  journal = {International Journal of Image, Graphics and Signal Processing},
  volume = {15},
  number = {4},
  pages = {44--58},
  issn = {20749074, 20749082},
  doi = {10.5815/ijigsp.2023.04.04},
  urldate = {2025-04-20},
  abstract = {Cancer is the second most found disease, and Breast cancer is the most common in women. Breast cancer is curable and can reduce mortality, but it needs to be identified early and treated accordingly. Radiologists use different modalities for the identification of Breast cancer. The superiority of Mammograms over other modalities is like minor radiation exposure and can identify different types of cancers. Therefore, mammograms are the most frequently used imaging modality for Breast Cancer Diagnosis. However, noise can be added while capturing the image, affecting the accuracy and analysis of the result. Therefore, using different filtering techniques to pre-process mammograms can enhance images and improve outcomes. For the study, the MIAS dataset has been used. This paper gives a comparative study on filters for Denoising and enhancement of mammograms. The study focuses on filters like Box Filter, Averaging filter, Gaussian Filter, Identical Filter, Convolutional 2D Filter, Median Filter, and Bilateral Filter. Performance measures used to compare these filters are Mean Squared Error (MSE), Structural Similarity Index Measure (SSIM), and Peak Signal-to-noise Ratio (PSNR). All Performance measures are evaluated for all images of MIAS dataset and compared accordingly. Results show that Gaussian Filter, Median Filter, and Bilateral Filter give better results than other filters.},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/7LCV4YVN/Institute of Technology, Nirma University, Ahmedabad, Gujarat, 382481, Ahmedabad, Gujarat, India et al. - 2023 - Mammogram Pre-processing Using filtering methods for Breast Cancer Diagnosis.pdf}
}

@article{khourdifi2024,
  title = {Early {{Breast Cancer Detection Based}} on {{Deep Learning}}: {{An Ensemble Approach Applied}} to {{Mammograms}}},
  shorttitle = {Early {{Breast Cancer Detection Based}} on {{Deep Learning}}},
  author = {Khourdifi, Youness and El Alami, Alae and Zaydi, Mounia and Maleh, Yassine and {Er-Remyly}, Omar},
  year = {2024},
  month = dec,
  journal = {BioMedInformatics},
  volume = {4},
  number = {4},
  pages = {2338--2373},
  issn = {2673-7426},
  doi = {10.3390/biomedinformatics4040127},
  urldate = {2025-04-20},
  abstract = {Background: Breast cancer is one of the leading causes of death in women, making early detection through mammography crucial for improving survival rates. However, human interpretation of mammograms is often prone to diagnostic errors. This study addresses the challenge of improving the accuracy of breast cancer detection by leveraging advanced machine learning techniques. Methods: We propose an extended ensemble deep learning model that integrates three state-of-the-art convolutional neural network (CNN) architectures: VGG16, DenseNet121, and InceptionV3. The model utilizes multi-scale feature extraction to enhance the detection of both benign and malignant masses in mammograms. This ensemble approach is evaluated on two benchmark datasets: INbreast and CBIS-DDSM. Results: The proposed ensemble model achieved significant performance improvements. On the INbreast dataset, the ensemble model attained an accuracy of 90.1\%, recall of 88.3\%, and an F1-score of 89.1\%. For the CBIS-DDSM dataset, the model reached 89.5\% accuracy and 90.2\% specificity. The ensemble method outperformed each individual CNN model, reducing both false positives and false negatives, thereby providing more reliable diagnostic results. Conclusions: The ensemble deep learning model demonstrated strong potential as a decision support tool for radiologists, offering more accurate and earlier detection of breast cancer. By leveraging the complementary strengths of multiple CNN architectures, this approach can improve clinical decision making and enhance the accessibility of high-quality breast cancer screening.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/T83FTGZM/Khourdifi et al. - 2024 - Early Breast Cancer Detection Based on Deep Learning An Ensemble Approach Applied to Mammograms.pdf}
}

@misc{lee2016,
  title = {Curated {{Breast Imaging Subset}} of {{Digital Database}} for {{Screening Mammography}} ({{CBIS-DDSM}}) [{{Data}} Set]. {{The Cancer Imaging Archive}}},
  author = {Lee, Rebecca Sawyer and Gimenez, Francisco and Hoogi, Assaf and Rubin, Daniel L},
  year = {2016},
  doi = {10.7937/K9/TCIA.2016.7O02S9CY},
  urldate = {2025-04-16}
}

@article{lee2017,
  title = {A Curated Mammography Data Set for Use in Computer-Aided Detection and Diagnosis Research},
  author = {Lee, Rebecca Sawyer and Gimenez, Francisco and Hoogi, Assaf and Miyake, Kanae Kawai and Gorovoy, Mia and Rubin, Daniel L.},
  year = {2017},
  month = dec,
  journal = {Scientific Data},
  volume = {4},
  number = {1},
  pages = {170177},
  issn = {2052-4463},
  doi = {10.1038/sdata.2017.177},
  urldate = {2025-04-18},
  abstract = {Abstract             Published research results are difficult to replicate due to the lack of a standard evaluation data set in the area of decision support systems in mammography; most computer-aided diagnosis (CADx) and detection (CADe) algorithms for breast cancer in mammography are evaluated on private data sets or on unspecified subsets of public databases. This causes an inability to directly compare the performance of methods or to replicate prior results. We seek to resolve this substantial challenge by releasing an updated and standardized version of the Digital Database for Screening Mammography (DDSM) for evaluation of future CADx and CADe systems (sometimes referred to generally as CAD) research in mammography. Our data set, the CBIS-DDSM (Curated Breast Imaging Subset of DDSM), includes decompressed images, data selection and curation by trained mammographers, updated mass segmentation and bounding boxes, and pathologic diagnosis for training data, formatted similarly to modern computer vision data sets. The data set contains 753 calcification cases and 891 mass cases, providing a data-set size capable of analyzing decision support systems in mammography.},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/CTPAYHXU/Lee et al. - 2017 - A curated mammography data set for use in computer-aided detection and diagnosis research.pdf}
}

@article{liao2024,
  title = {An Open Codebase for Enhancing Transparency in Deep Learning-Based Breast Cancer Diagnosis Utilizing {{CBIS-DDSM}} Data},
  author = {Liao, Ling and Aagaard, Eva M.},
  year = {2024},
  month = nov,
  journal = {Scientific Reports},
  volume = {14},
  number = {1},
  pages = {27318},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-78648-0},
  urldate = {2025-04-18},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/8G53YLYL/Liao and Aagaard - 2024 - An open codebase for enhancing transparency in deep learning-based breast cancer diagnosis utilizing.pdf}
}

@misc{MaiurilorenzoCBISDDSMCNNHugging,
  title = {Maiurilorenzo/{{CBIS-DDSM-CNN}} {$\cdot$} {{Hugging Face}}},
  urldate = {2025-04-20},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/maiurilorenzo/CBIS-DDSM-CNN},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/69BJHURH/CBIS-DDSM-CNN.html}
}

@article{murty2024,
  title = {Integrative Hybrid Deep Learning for Enhanced Breast Cancer Diagnosis: Leveraging the {{Wisconsin Breast Cancer Database}} and the {{CBIS-DDSM}} Dataset},
  shorttitle = {Integrative Hybrid Deep Learning for Enhanced Breast Cancer Diagnosis},
  author = {Murty, Patnala S. R. Chandra and Anuradha, Chinta and Naidu, P. Appala and Mandru, Deenababu and Ashok, Maram and Atheeswaran, Athiraja and Rajeswaran, Nagalingam and Saravanan, V.},
  year = {2024},
  month = nov,
  journal = {Scientific Reports},
  volume = {14},
  number = {1},
  pages = {26287},
  issn = {2045-2322},
  doi = {10.1038/s41598-024-74305-8},
  urldate = {2025-04-20},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/YCGSDHAW/Murty et al. - 2024 - Integrative hybrid deep learning for enhanced breast cancer diagnosis leveraging the Wisconsin Brea.pdf}
}

@article{rafid2022,
  title = {An {{Effective Ensemble Machine Learning Approach}} to {{Classify Breast Cancer Based}} on {{Feature Selection}} and {{Lesion Segmentation Using Preprocessed Mammograms}}},
  author = {Rafid, A. K. M. Rakibul Haque and Azam, Sami and Montaha, Sidratul and Karim, Asif and Fahim, Kayes Uddin and Hasan, Md. Zahid},
  year = {2022},
  month = nov,
  journal = {Biology},
  volume = {11},
  number = {11},
  pages = {1654},
  issn = {2079-7737},
  doi = {10.3390/biology11111654},
  urldate = {2025-04-20},
  abstract = {Background: Breast cancer, behind skin cancer, is the second most frequent malignancy among women, initiated by an unregulated cell division in breast tissues. Although early mammogram screening and treatment result in decreased mortality, differentiating cancer cells from surrounding tissues are often fallible, resulting in fallacious diagnosis. Method: The mammography dataset is used to categorize breast cancer into four classes with low computational complexity, introducing a feature extraction-based approach with machine learning (ML) algorithms. After artefact removal and the preprocessing of the mammograms, the dataset is augmented with seven augmentation techniques. The region of interest (ROI) is extracted by employing several algorithms including a dynamic thresholding method. Sixteen geometrical features are extracted from the ROI while eleven ML algorithms are investigated with these features. Three ensemble models are generated from these ML models employing the stacking method where the first ensemble model is built by stacking ML models with an accuracy of over 90\% and the accuracy thresholds for generating the rest of the ensemble models are {$>$}95\% and {$>$}96. Five feature selection methods with fourteen configurations are applied to notch up the performance. Results: The Random Forest Importance algorithm, with a threshold of 0.045, produces 10 features that acquired the highest performance with 98.05\% test accuracy by stacking Random Forest and XGB classifier, having a higher than {$>$}96\% accuracy. Furthermore, with K-fold cross-validation, consistent performance is observed across all K values ranging from 3--30. Moreover, the proposed strategy combining image processing, feature extraction and ML has a proven high accuracy in classifying breast cancer.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/PUMUPZER/Rafid et al. - 2022 - An Effective Ensemble Machine Learning Approach to Classify Breast Cancer Based on Feature Selection.pdf}
}

@misc{ronneberger2015,
  title = {U-{{Net}}: {{Convolutional Networks}} for {{Biomedical Image Segmentation}}},
  shorttitle = {U-{{Net}}},
  author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  year = {2015},
  month = may,
  number = {arXiv:1505.04597},
  eprint = {1505.04597},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1505.04597},
  urldate = {2025-04-25},
  abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/37I8RFNC/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf;/Users/tkshfj/Dropbox/Zotero/storage/S9QBNYY6/1505.html}
}

@misc{scolocke2021,
  title = {Scolocke/Tumor\_classification},
  author = {{scolocke}},
  year = {2021},
  month = sep,
  urldate = {2025-04-20}
}

@article{shen2019,
  title = {Deep {{Learning}} to {{Improve Breast Cancer Detection}} on {{Screening Mammography}}},
  author = {Shen, Li and Margolies, Laurie R. and Rothstein, Joseph H. and Fluder, Eugene and McBride, Russell and Sieh, Weiva},
  year = {2019},
  month = aug,
  journal = {Scientific Reports},
  volume = {9},
  number = {1},
  pages = {12495},
  issn = {2045-2322},
  doi = {10.1038/s41598-019-48995-4},
  urldate = {2025-04-20},
  abstract = {Abstract                            The rapid development of deep learning, a family of machine learning techniques, has spurred much interest in its application to medical imaging problems. Here, we develop a deep learning algorithm that can accurately detect breast cancer on screening mammograms using an ``end-to-end'' training approach that efficiently leverages training datasets with either complete clinical annotation or only the cancer status (label) of the whole image. In this approach, lesion annotations are required only in the initial training stage, and subsequent stages require only image-level labels, eliminating the reliance on rarely available lesion annotations. Our all convolutional network method for classifying screening mammograms attained excellent performance in comparison with previous methods. On an independent test set of digitized film mammograms from the Digital Database for Screening Mammography (CBIS-DDSM), the best single model achieved a per-image AUC of 0.88, and four-model averaging improved the AUC to 0.91 (sensitivity: 86.1\%, specificity: 80.1\%). On an independent test set of full-field digital mammography (FFDM) images from the INbreast database, the best single model achieved a per-image AUC of 0.95, and four-model averaging improved the AUC to 0.98 (sensitivity: 86.7\%, specificity: 96.1\%). We also demonstrate that a whole image classifier trained using our end-to-end approach on the CBIS-DDSM digitized film mammograms can be transferred to INbreast FFDM images using only a subset of the INbreast data for fine-tuning and without further reliance on the availability of lesion annotations. These findings show that automatic deep learning methods can be readily trained to attain high accuracy on heterogeneous mammography platforms, and hold tremendous promise for improving clinical tools to reduce false positive and false negative screening mammography results. Code and model available at:               https://github.com/lishen/end2end-all-conv               .},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/92QVWQD4/Shen et al. - 2019 - Deep Learning to Improve Breast Cancer Detection on Screening Mammography.pdf}
}

@article{thirumalaisamy2023,
  title = {Breast {{Cancer Classification Using Synthesized Deep Learning Model}} with {{Metaheuristic Optimization Algorithm}}},
  author = {Thirumalaisamy, Selvakumar and Thangavilou, Kamaleshwar and Rajadurai, Hariharan and Saidani, Oumaima and Alturki, Nazik and Mathivanan, Sandeep Kumar and Jayagopal, Prabhu and Gochhait, Saikat},
  year = {2023},
  month = sep,
  journal = {Diagnostics},
  volume = {13},
  number = {18},
  pages = {2925},
  issn = {2075-4418},
  doi = {10.3390/diagnostics13182925},
  urldate = {2025-04-20},
  abstract = {Breast cancer is the second leading cause of mortality among women. Early and accurate detection plays a crucial role in lowering its mortality rate. Timely detection and classification of breast cancer enable the most effective treatment. Convolutional neural networks (CNNs) have significantly improved the accuracy of tumor detection and classification in medical imaging compared to traditional methods. This study proposes a comprehensive classification technique for identifying breast cancer, utilizing a synthesized CNN, an enhanced optimization algorithm, and transfer learning. The primary goal is to assist radiologists in rapidly identifying anomalies. To overcome inherent limitations, we modified the Ant Colony Optimization (ACO) technique with opposition-based learning (OBL). The Enhanced Ant Colony Optimization (EACO) methodology was then employed to determine the optimal hyperparameter values for the CNN architecture. Our proposed framework combines the Residual Network-101 (ResNet101) CNN architecture with the EACO algorithm, resulting in a new model dubbed EACO--ResNet101. Experimental analysis was conducted on the MIAS and DDSM (CBIS-DDSM) mammographic datasets. Compared to conventional methods, our proposed model achieved an impressive accuracy of 98.63\%, sensitivity of 98.76\%, and specificity of 98.89\% on the CBIS-DDSM dataset. On the MIAS dataset, the proposed model achieved a classification accuracy of 99.15\%, a sensitivity of 97.86\%, and a specificity of 98.88\%. These results demonstrate the superiority of the proposed EACO--ResNet101 over current methodologies.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/TGPMVPJ4/Thirumalaisamy et al. - 2023 - Breast Cancer Classification Using Synthesized Deep Learning Model with Metaheuristic Optimization A.pdf}
}

@misc{tsochatzidis2025,
  title = {Lazatsoc/Cbis\_ddsm\_dataloader},
  author = {Tsochatzidis, Lazaros},
  year = {2025},
  month = mar,
  urldate = {2025-04-20}
}

@article{wang2024,
  title = {Mammography with Deep Learning for Breast Cancer Detection},
  author = {Wang, Lulu},
  year = {2024},
  month = feb,
  journal = {Frontiers in Oncology},
  volume = {14},
  pages = {1281922},
  issn = {2234-943X},
  doi = {10.3389/fonc.2024.1281922},
  urldate = {2025-04-18},
  abstract = {X-ray mammography is currently considered the golden standard method for breast cancer screening, however, it has limitations in terms of sensitivity and specificity. With the rapid advancements in deep learning techniques, it is possible to customize mammography for each patient, providing more accurate information for risk assessment, prognosis, and treatment planning. This paper aims to study the recent achievements of deep learning-based mammography for breast cancer detection and classification. This review paper highlights the potential of deep learning-assisted X-ray mammography in improving the accuracy of breast cancer screening. While the potential benefits are clear, it is essential to address the challenges associated with implementing this technology in clinical settings. Future research should focus on refining deep learning algorithms, ensuring data privacy, improving model interpretability, and establishing generalizability to successfully integrate deep learning-assisted mammography into routine breast cancer screening programs. It is hoped that the research findings will assist investigators, engineers, and clinicians in developing more effective breast imaging tools that provide accurate diagnosis, sensitivity, and specificity for breast cancer.},
  langid = {english},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/8EZ5QHK9/Wang - 2024 - Mammography with deep learning for breast cancer detection.pdf}
}

@misc{Yuyuyu123456CBISDDSM,
  title = {Yuyuyu123456/{{CBIS-DDSM}}},
  urldate = {2025-04-20},
  howpublished = {https://github.com/yuyuyu123456/CBIS-DDSM},
  file = {/Users/tkshfj/Dropbox/Zotero/storage/SEJMH57U/CBIS-DDSM.html}
}
