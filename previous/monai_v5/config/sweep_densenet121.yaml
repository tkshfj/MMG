# sweep_densenet121.yaml
program: main.py
method: bayes

metric:
  name: val/auc
  goal: maximize

parameters:
  # Fixed experiment knobs
  architecture: {value: densenet121}
  task: {value: classification}
  run_cap: {value: 20}

  # Execution
  epochs: {value: 40}
  num_workers: {value: 12}
  debug: {value: true}
  debug_transforms: {value: false}
  console_iter_log: {value: false}
  console_epoch_log: {value: true}
  seed: {value: 42}

  # Two-pass validation / calibration
  two_pass_val: {value: true}
  log_calibrated: {value: true}

  calibration_method:
    values: ["youden", "f1", "rate_match"]
  cal_q_bounds: {value: [0.10, 0.90]}
  cal_min_tp: {values: [5, 10, 20]}
  cal_bootstraps: {values: [0, 25]}

  cal_warmup_epochs: {values: [1, 2, 3]}
  cal_init_threshold: {values: [0.40, 0.50, 0.60]}
  cal_ema_beta: {values: [0.10, 0.20, 0.30]}
  cal_max_delta: {values: [0.05, 0.10, 0.20]}
  cal_rate_tolerance: {values: [0.08, 0.10, 0.12, 0.15]}
  cal_auc_floor: {values: [0.50, 0.52, 0.55]}
  cal_fallback: {values: ["rate_match", "keep_last"]}

  # Data / labels
  in_channels: {value: 1}
  input_shape: {value: [256, 256]}
  num_classes: {value: 2}
  class_counts: {value: [331, 232]}
  class_balance: {value: inverse}
  batch_size: {values: [32, 64]}

  # Model (DenseNet121)
  pretrained: {values: [false, true]}

  # Loss weighting
  alpha: {values: [1.0, 2.0]}
  beta:  {values: [0.5, 1.0]}
  multi_weight: {value: 0.65}

  # Optimizer / weight decay
  optimizer: {value: adamw}
  weight_decay:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.001

  # Param-group strategy
  param_groups: {value: split}  # or values: [single, split]
  base_lr:
    distribution: log_uniform_values
    min: 0.00003
    max: 0.0003
  head_multiplier: {values: [5, 10, 15]}
  head_lr_scale: 0.5       # lower LR on head
  head_wd_scale: 1.5       # slightly higher WD on head
  head_keys: ["head","classifier","mlp_head","fc","cls"]  # optional

  # Single-group LR
  lr:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.003

  # Split LRs
  # base_lr:
  #   distribution: log_uniform_values
  #   min: 0.00002
  #   max: 0.0001
  # head_multiplier: {values: [5.0, 10.0, 15.0]}

  # LR scheduler
  lr_scheduler: {values: ["none", "cosine", "warmcos", "plateau"]}

  # Cosine params
  T_max: {value: 40}
  eta_min: {value: 0.0}

  # Warmup params
  warmup_epochs: {values: [0, 2, 3]}
  warmup_start_factor: {values: [0.1, 0.2]}

  # Plateau params
  plateau_metric: {value: val/loss}
  plateau_mode:   {value: min}
  patience: {values: [3, 6]}
  factor:   {values: [0.5, 0.3]}
  threshold: {value: 0.0001}

  # Classification decision defaults
  binary_single_logit: {value: true}
  binary_bce_from_two_logits: {value: false}
  cls_loss: {value: auto}
  cls_decision:  {value: threshold}
  cls_threshold: {value: 0.5}
  positive_index: {value: 1}
