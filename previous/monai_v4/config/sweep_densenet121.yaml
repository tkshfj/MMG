# sweep_densenet121.yaml
program: main.py
method: bayes

metric:
  name: val/auc
  goal: maximize

parameters:
  # --- Core / execution ---
  architecture:        { value: densenet121 }
  task:                { value: classification }
  run_cap:             { value: 20 }
  epochs:              { value: 40 }
  num_workers:         { value: 12 }
  debug:               { value: true }
  debug_transforms:    { value: false }

  # --- Data / labels ---
  in_channels:         { value: 1 }
  input_shape:         { value: [256, 256] }
  num_classes:         { value: 2 }
  class_counts:        { value: [331, 232] }   # enables inverse-freq CE weights (+ optional bias init if implemented)
  batch_size:
    values: [32, 64]

  # --- Model (DenseNet121) ---
  pretrained:
    values: [false, true]

  # --- Loss weighting (read by centralized get_loss_fn) ---
  alpha:        { values: [1.0, 2.0] }
  beta:         { values: [0.5, 1.0] }
  multi_weight: { value: 0.65 }  # used only if combined metric is enabled

  # --- Optimizer / weight decay ---
  optimizer: { value: adamw }
  weight_decay:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.001

  # --- Param-group strategy (optimizer LR layout) ---
  # "single": one LR for all params (use `lr`)
  # "split" : backbone/base LR + head LR = base_lr * head_multiplier
  param_groups:
    values: ["single", "split"]

  # Single-group LR (used when param_groups == "single")
  lr:
    distribution: log_uniform_values
    min: 0.0001
    max: 0.003

  # Split LRs (used when param_groups == "split")
  base_lr:
    distribution: log_uniform_values
    min: 0.00002
    max: 0.0001
  head_multiplier:
    values: [5.0, 10.0, 15.0]

  # --- LR scheduler (epoch-level) ---
  # "none"    : fixed LR(s)
  # "cosine"  : CosineAnnealingLR(T_max, eta_min)
  # "warmcos" : Linear warmup â†’ cosine
  # "plateau" : ReduceLROnPlateau(monitor, factor, patience)
  scheduler:
    values: ["none", "cosine", "warmcos", "plateau"]

  # Cosine-only params (used by "cosine" and cosine part of "warmcos")
  T_max:   { value: 40 }   # usually tie to epochs
  eta_min: { value: 0.0 }

  # Warmup (only when scheduler == "warmcos")
  warmup_epochs:       { values: [0, 2, 3] }
  warmup_start_factor: { values: [0.1, 0.2] }

  # Plateau (only when scheduler == "plateau")
  monitor:      { value: val_loss }
  monitor_mode: { value: min }
  patience:     { values: [3, 6] }
  factor:       { values: [0.5, 0.3] }

# Early termination to save budget
early_terminate:
  type: hyperband
  min_iter: 4
