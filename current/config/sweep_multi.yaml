# sweep_test.yaml
program: main.py
method: bayes

metric:
  name: val_multi
  goal: maximize

parameters:
  # Core experiment settings
  architecture:
    value: multitask_unet
  task:
    value: multitask
  run_cap:
    value: 1
  debug:
    value: true
  debug_transforms:
    value: false   # set true only when a one-off check needed
  # class_counts:
  #   value: [n0, n1]    # enables prior-bias init + inverse-freq weights
  # class_weights:
  #   value: [w0, w1]

  # Data settings
  input_shape:
    value: [256, 256]
  in_channels:
    value: 1
  patch_size:
    value: 16  # or [16, 16]
  num_classes:
    value: 2
  num_workers:
    value: 2

  # Fixed hyperparameters
  epochs:
    value: 40
  base_learning_rate:
    value: 0.0002
  multi_weight:
    value: 0.65

  # Tunable hyperparameters
  batch_size:
    values: [16, 32, 64]

  lr_multiplier:
    distribution: uniform
    min: 0.8    # 0.95
    max: 1.2    # 1.10

  dropout:
    distribution: uniform
    min: 0.15   # 0.17
    max: 0.25   # 0.20

  l2_reg:
    distribution: uniform
    min: 0.00001   # 0.00006
    max: 0.00012

  # Loss weighting hyperparameters
  alpha:
    values: [0.5, 1.0, 2.0]
    # distribution: uniform
    # min: 1.6
    # max: 2.0

  beta:
    values: [0.5, 1.0, 2.0]
    # distribution: uniform
    # min: 0.8
    # max: 1.4


# config:
#   early_stop:
#     patience: 10
#     min_delta: 0.001
#     metric: val_auc
#     mode: max


# program: train.py
# method: bayes

# metric:
#   name: val_auc
#   goal: maximize

# parameters:
#   # Experiment settings
#   architecture:
#     value: multitask_unet
#   task:
#     value: multitask
#   run_cap:
#     value: 20
#   num_workers:
#     value: 4

#   # Fixed hyperparameters
#   epochs:
#     value: 40
#   input_shape:
#     value: [256, 256]
#   num_classes:
#     value: 2

#   # Tunable hyperparameters
#   batch_size:
#     values: [16, 32, 64]

#   base_learning_rate:
#     value: 0.0002

#   lr_multiplier:
#     distribution: uniform
#     min: 0.8    # 0.95
#     max: 1.2    # 1.10

#   dropout:
#     distribution: uniform
#     min: 0.15   # 0.17
#     max: 0.25   # 0.20

#   l2_reg:
#     distribution: uniform
#     min: 0.00001   # 0.00006
#     max: 0.00012

#   # Loss weighting hyperparameters
#   alpha:
#     values: [0.5, 1.0, 2.0]
#     # distribution: uniform
#     # min: 1.6
#     # max: 2.0

#   beta:
#     values: [0.5, 1.0, 2.0]
#     # distribution: uniform
#     # min: 0.8
#     # max: 1.4
