# sweep_mtlunet.yaml
program: main.py
method: bayes

metric:
  name: val/multi
  goal: maximize

# Disable early termination cleanly (schema-safe)
# early_terminate:
  # value: none  # use HyperBand here only if you actually want it

parameters:
  # ---------------- Fixed experiment knobs ----------------
  architecture: {value: multitask_unet}
  task: {value: multitask}
  run_cap: {value: 20}

  # ---------------- Execution ----------------
  epochs: {value: 40}
  num_workers: {value: 8}
  debug: {value: true}
  debug_transforms: {value: false}
  console_iter_log: {value: false}
  console_epoch_log: {value: true}
  seed: {value: 42}

  # ---------------- Two-pass validation / calibration ----------------
  two_pass_val: {value: true}
  log_calibrated: {value: true}

  calibration_method:
    values: ["youden", "f1", "rate_match"]
  cal_q_bounds: {value: [0.10, 0.90]}
  cal_min_tp: {values: [5, 10, 20]}
  cal_bootstraps: {values: [0, 25]}

  cal_warmup_epochs: {values: [1, 2, 3]}
  cal_init_threshold: {values: [0.40, 0.50, 0.60]}
  cal_ema_beta: {values: [0.10, 0.20, 0.30]}
  cal_max_delta: {values: [0.05, 0.10, 0.20]}
  cal_rate_tolerance: {values: [0.08, 0.10, 0.12, 0.15]}
  cal_auc_floor: {values: [0.50, 0.52, 0.55]}
  cal_fallback: {values: ["rate_match", "keep_last"]}

  # ---------------- Data / model topology ----------------
  in_channels: {value: 1}
  input_shape: {value: [256, 256]}
  num_classes: {value: 2}
  class_balance: {value: inverse}
  batch_size: {values: [32, 64]}

  # Binary classifier head behavior
  binary_single_logit: {value: true}
  binary_bce_from_two_logits: {value: false}

  # ---------------- Loss options ----------------
  cls_loss: {value: auto}
  # pos_weight: {value: 1.7}  # optional override (usually omit)

  # ---------------- Segmentation post-process ----------------
  seg_threshold: {value: 0.5}

  # ---------------- Multi-task / objective ----------------
  multi_weight: {value: 0.65}
  alpha: {values: [1.0, 2.0]}
  beta:  {values: [0.5, 1.0]}

  # ---------------- Core tunables ----------------
  lr:
    distribution: log_uniform_values
    min: 0.00003
    max: 0.0008
  weight_decay:
    distribution: log_uniform_values
    min: 0.00001
    max: 0.00005
  dropout_rate:
    distribution: uniform
    min: 0.18
    max: 0.24

  # ---------------- LR scheduler ----------------
  lr_scheduler: {values: ["none", "cosine", "warmcos", "plateau"]}

  # Cosine params
  T_max: {value: 40}
  eta_min: {value: 0.0}

  # Warmup params (used by warmcos)
  warmup_epochs: {values: [0, 2, 3]}
  warmup_start_factor: {values: [0.1, 0.2]}

  # Plateau params (only meaningful when lr_scheduler=plateau)
  plateau_metric: {value: val/auc}
  plateau_mode:   {value: max}
  patience: {value: 0}
  factor:   {values: [0.5, 0.3]}
  plateau_threshold: {values: [0.0001, 0.0005]}

  # ---------------- Classification decision defaults (std pass) ----------------
  cls_decision:  {value: threshold}
  cls_threshold: {value: 0.5}
  positive_index: {value: 1}

# program: main.py
# method: bayes

# metric:
#   name: val/multi
#   goal: maximize

# early_terminate:
#   type: none  # hyperband
#   # min_iter: 4

# parameters:
#   # ---------------- Fixed experiment knobs ----------------
#   architecture: {value: multitask_unet}
#   task: {value: multitask}
#   run_cap: {value: 20}

#   # ---------------- Execution ----------------
#   epochs: {value: 40}
#   num_workers: {value: 8}
#   debug: {value: true}
#   debug_transforms: {value: false}
#   console_iter_log: {value: false}
#   console_epoch_log: {value: true}
#   seed: {value: 42}

#   # ---------------- Two-pass validation / calibration ----------------
#   two_pass_val: {value: true}          # enables calibration pass
#   log_calibrated: {value: true}        # log calibrated cls metrics

#   # Calibrator core
#   calibration_method:
#     values: ["youden", "f1", "rate_match"]
#   cal_q_bounds:
#     value: [0.10, 0.90]                # window for threshold candidates
#   cal_min_tp:
#     values: [5, 10, 20]                # F1 guardrail
#   cal_bootstraps:
#     values: [0, 25]                    # 0 = off, else median over bootstraps

#   # Stability guards
#   cal_warmup_epochs:
#     values: [1, 2, 3]
#   cal_init_threshold:
#     values: [0.40, 0.50, 0.60]
#   cal_ema_beta:
#     values: [0.10, 0.20, 0.30]
#   cal_max_delta:
#     values: [0.05, 0.10, 0.20]

#   # Rate guard (keeps pos_rate near base rate)
#   cal_rate_tolerance:
#     values: [0.08, 0.10, 0.12, 0.15]

#   # Weak-AUC handling
#   cal_auc_floor:
#     values: [0.50, 0.52, 0.55]
#   cal_fallback:
#     values: ["rate_match", "keep_last"]

#   # ---------------- Data / model topology ----------------
#   in_channels: {value: 1}
#   input_shape: {value: [256, 256]}
#   num_classes: {value: 2}
#   # class_counts: {value: [331, 232]}     # drives base rate & pos_weight derivation
#   class_balance: {value: inverse}       # inverse | effective | none

#   # Binary classifier head behavior
#   binary_single_logit: {value: true}    # emit 1 logit for binary classification
#   binary_bce_from_two_logits: {value: false}  # bridge legacy 2-logit â†’ BCE (pos-neg)

#   # ---------------- Loss options ----------------
#   cls_loss: {value: auto}               # auto | bce | ce | focal
#   # pos_weight: {value: 1.7}            # optional manual override (usually omit)

#   # ---------------- Segmentation post-process ----------------
#   seg_threshold: {value: 0.5}           # for sigmoid binary seg

#   # ---------------- Multi-task / objective ----------------
#   multi_weight: {value: 0.65}           # weight for Dice in val/multi
#   alpha: {values: [1.0, 2.0]}           # cls loss weight
#   beta:  {values: [0.5, 1.0]}           # seg loss weight

#   # ---------------- Core tunables ----------------
#   batch_size: {values: [32, 64]}
#   lr:
#     distribution: log_uniform_values
#     min: 0.00003
#     max: 0.0008
#   weight_decay:
#     distribution: log_uniform_values
#     min: 0.00001
#     max: 0.00005
#   dropout_rate:
#     distribution: uniform
#     min: 0.18
#     max: 0.24

#   # ---------------- LR scheduler ----------------
#   lr_scheduler: {values: ["none", "cosine", "warmcos", "plateau"]}
#   # lr_scheduler: {value: "plateau"}

#   # Cosine params
#   T_max: {value: 40}
#   eta_min: {value: 0.0}

#   # Warmup params (used when warmcos)
#   warmup_epochs: {values: [0, 2, 3]}
#   warmup_start_factor: {values: [0.1, 0.2]}

#   # Plateau params
#   plateau_metric: {value: val/auc}         # trainer.state.metrics key; two-pass stores 'loss'
#   plateau_mode:   {value: max}          # min | max
#   patience: {value: 0}  # {values: [3, 6]}
#   factor:   {values: [0.5, 0.3]}
#   plateau_threshold:
#       values: [0.0001, 0.0005]  # only meaningful when lr_scheduler=plateau

#   # ---------------- Classification decision defaults (std pass) ----------------
#   # Two-pass will overwrite threshold each epoch via cal_thr when available.
#   cls_decision:  {value: threshold}     # "argmax" | "threshold"
#   cls_threshold: {value: 0.5}
#   positive_index: {value: 1}            # ignored for single-logit, used for 2-logit

